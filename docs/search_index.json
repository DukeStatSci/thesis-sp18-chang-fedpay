[
["abstract.html", "Abstract", " Abstract The preface pretty much says it all. Second paragraph of abstract starts here. "],
["1-introduction.html", "Chapter 1 Introduction", " Chapter 1 Introduction Background of the Senior Executive Service (SES) Program The Senior Executive Service (SES) was established by the Civil Service Reform Act (CSRA) in 1978. The introduction of the CSRA is to select and develop high-level executives corps with exceptional management skills. Members of the SES, granted with high authority, not only ensure productivity and efficiency within the government but also provide leadership to agencies across administration. Each executive holds key position below the top political appointees, and serves as primary link between these appointees and government career workers. (“Guide to the senior executive service,” 2017) Before the existence of the SES, the federal government was a fragmented bureaucracy. The creation of these centralized senior leaders therefore brings a “measure of coherence” to fulfil the larger corporate interests of the federal government. (Carey, 2011) With more than thirty years of establishment, the SES becomes “the backbone of Federal executive leadership”, where its members “play a crucial role in addressing unprecedented challenges facing our nation.” (“Statement of Jeffrey D. Zients, U.S. Congress, Senate Committee on Homeland Security and Governmental Affairs, Subcommittee on Oversight of Government Management, the Federal Workforce, and the District of Columbia,” 2011) The Office of Personnel Management (OPM), also established by the CSRA, is tasked to manage the overall SES program. Currently, there are four types of appointments in the SES. The first type is career appointment, where incumbents are selected through merit-based staffing and usually hold permanent position within the government. The other three types are either non-career appointment or appointment with limited terms. Since the majority of positions in the SES is made up of career appointments, the primary interest of this study would focus on career track SES. Challenges of the SES Program The selection process of the SES is usually rigorous. Currently, the selection of career appointment in the SES is based on OPM’s Executive Core Qualifications (ECQ), which specifies a candidate’s competencies to build successful teams and bring out strategic integration within and outside the organization. Specifically, the OPM identifies various critical leadership skills for executives to succeed. For example, executives need to have the abilities to lead strategic changes and achieve organizational goals with high-quality results. The approval of a candidate is further reviewed by Qualifications Review Boards (QRBs), consisting of three SES members from distinct agencies. While the recruiting of the SES position consists of multiple phases, the effectiveness of the SES recruiting is doubtful. For example, promotion bias towards people with technical expertise existed in the early establishment of the SES program. Furthermore, some of the outside observers have raised concern about the diversity of the SES. As a result, various studies have been conducted on the current SES system. For example, Powell and Butterfield investigated the impact of gender on the promotion decisions of the SES positions. (Powell &amp; Butterfield, 1994) Shafritz argued that the quality of the SES can be improved with more racial, ethnic and gender diversity. (Carey, 2011) Goal of the study The motivation behind this project is twofold: first, to understand what factors influence the promotion outcome of the SES positions, and second, to delve into the gender and racial diversity of the SES recruiting. "],
["2-data.html", "Chapter 2 Data 2.1 Introduction of Data 2.2 Identify Sub-population 2.3 Missing Data 2.4 Assessing Missing Data 2.5 Addressing Missing Data", " Chapter 2 Data 2.1 Introduction of Data The data of this study comes from the Office of Personal Management (OPM), consisting of the federal employees data from 1988 to 2011. It contains not only an employee’s personal information such as gender and race but also career-related information such as years of services, pay plan, and salary. Below are brief descriptions of each variable. Personal Information Variable Name Short Description Type Sex gender of an employee categorical Race race or national origin of an employee categorical Education educational degree an employee obtained categorical Career-related Information Variable Name Short Description Type Start Year fiscal year an employee started working continuous Service Fiscal Year Count number of years an employee has worked in the government excluding any break in services continuous Department Switch number of times an employee switched department continuous Occupational Category occupational category based on the nature of the work categorical Pay Plan a two-dimensional matrix of basic pay rates for certain employees prescribed by law or other authoritative sources categorical Grade hierarchical relationships among positions covered by the same pay plan or system categorical Step Rate an indicator of salary range within certain pay plan and grade categorical Pay Basic an employee’s basic pay rate adjusted for inflation based on 2011 standard continuous Promoted an indicator variable of whether an employee has ever been promoted into the Senior Executive Service (SES) position categorical 2.2 Identify Sub-population The underlying goal of this study is to better understand the SES promotion outcomes without political sponsorship. Currently, the SES positions account for less than 1 percent of all positions in the government. With such low proportion, it is important to identify potential candidates before conducting statistical modeling and inference. First, we define our population to be career-track employees whose starting years are between 1978 to 1997 and have at least 15 years of working experiences in the federal government. The reasons to choose this time period are twofold. First, the average number of working year for an employee to get promoted is around 22 years. (Powell &amp; Butterfield, 1994) 2011 is the last year recorded in the OPM data, so employees who start after 1997 would have less than 15 years of working experiences. Since these people are unlikely to be promoted within such a short period of time, it is appropriate to remove them. Second, the OPM database was not established until 1988, so obtaining information of employees who start in the 1950s or 1960s periods would be challenging. Furthermore, the characteristics of employees in the past are much different from employees nowadays. For example, the attainment of higher education and the proportion of women working are significantly higher nowadays. Given such constraints, we exclude employees whose starting year are before 1978. Second, though it usually takes more than 10 years for a federal employee to get promoted into the SES position, we did recognize that very few employees achieved the SES position with less than 10 years of working experiences. These employees might provide valuable information to the analysis, but we decided to remove them because we are more interested in understanding the long-term career promotion process. Third, we observed that employees who have been promoted into the SES positions usually made significant progress in their mid-career, which can be illustrated by features such as salary and grade achieved at working year 10. As mentioned in the Data section, an employee’s grade demonstrates the hierarchical relationships among positions covered by the same pay plan or system. For example, the grades for General Pay Schedule (GS and GM) pay plans range from 1 to 15, with 15 being the highest. Since both pay plans account for approximately 75% of the employees in the data, we can gain some insights from the grade distribution of employees with GS or GM pay plan at working year 10. Specifically, most employees with GS or GM pay plan and were later promoted into the SES position achieved grade 13 and above at working year 10, with few between grade 9 to 12, and none below grade 8. This indicates that employees with GS or GM pay plan who do not achieve grade 9 and above at working year 10 have very limited chance of getting promoted; therefore, we find it suitable to exclude them. Grade achieved at yr10 for employees who were later promoted into the SES position with GS or GM pay plan Grade 1-8 Grade 9 Grade 10 Grade 11 Grade 12 Grade 13 Grade 14 Grade 15 0 5 2 16 50 96 126 146 Lastly, the federal government classifies each employee’s occupation into five occupational categories based on the nature of the work. Respectively, they are Blue collar, Professional, Administrative, Technical, Clerical, and Other white collar. The detailed descriptions of each occupational category are shown in the table below. Since none of the SES positions contain Blue collar occupational category and less than one percent contains Technical and Clerical, employees in these categories should be removed from the data. Occupational Categories Occupational Category Description Blue collar Occupations comprising the trades, crafts, and manual labor Professional White collar occupations that require knowledge in a field of science or learning characteristically acquired through education or training equivalent to a bachelor’s or higher degree with major study in or pertinent to the specialized field Administrative White collar occupations that involve the exercise of analytical ability, judgment, discretion, and personal responsibility, and the application of a substantial body of knowledge of principles, concepts, and practices applicable to one of more fields of administration or management Technical White collar occupations that involve work typically associated with and supportive of a professional or administrative field Clerical White collar occupations that involve structured work in support of office, business, or fiscal operations Other white collar White collar occupations that cannot be related to the above professional, administrative, technical, or clerical categories 2.3 Missing Data Missing data is common in the social science research due to survey item-nonresponse or data recording errors. Missing data is no exception for the OPM data. Based on the mechanisms of missing data, Rubin defined three types of missing mechanisms: missing completely at random (MCAR), missing at random (MAR), and not missing at random (NMAR). (Little &amp; Rubin, 2014) First, data has MCAR property when the probability of observations being missing is unrelated to other subjects in the study. Second, data has MAR property when the probability of missing only depends on observed values but not on unobserved values. Though there are no formal ways to verify the MAR property, it is usually a reasonable assumption when we do not have comprehensive knowledge of the data. Lastly, data that cannot be attributed to either MCAR or MCAR has NMAR property, where the probability of missing depends on both observed and unobserved values. 2.4 Assessing Missing Data To make assumption of the missing mechanisms of the OPM data, it is crucial to understand when and why variables are missing. We achieve this step through examining the nature of the data and the missing patterns of each variable. The missingness of the OPM data is scattered, and the percentage of missing varies substantially. Given the nature of the data, the missingness can be summarized into two categories. The first category is inherent missingness. The OPM data contain more than 20 years of federal employees’ information. As rules and standards change overtime, missing data caused by recording errors is unavoidable. Particularly, this category applies to the missing of Race and Education variables, which are usually independent of time. The second category of the missingness is due to time constraint. The OPM data was not created until 1988, so part of the information for those who started before 1988 would not be recorded. For example, if an employee started in 1980 and worked until 1990, the OPM would only record this employee’s information from 1988 to 1990, whereas data from 1980 to 1987 would be missing. The missing of variables such as salary and grade that change overtime belongs to this category. Inherent Missingness Independent of Time The recording of race was originally classified into 16 categories, but new standard established in 2016 simplified it into 6 categories. The change of recording standard therefore leads to missing data. Our strategy to address the race variable is to convert the old recording standard into the new standard. However, even after the conversion, small percentage (less than 0.01%) of the race data is still missing. Education is another variable that has missing data. Some federal employees might pursue higher-level education while working in the government. In the OPM data, around 0.65 percent of the education data is missing. (Figure ??) Missingness due to Time Constraint Pay plan, grade, step rate, and salary are variables with missing data due to time constraint. Within certain pay plan, an employee’s salary information is determined by certain grade and step rate. Since all four variables are related with each other, the percentage of missing data for them should be generally the same overtime. Specifically, the proportion of missingness increases as year decreases. (Figure ??) This corresponds to the fact that the earliest recorded year in the OPM data is 1988, but employees who started before 1988 are also included. Regardless of time constraint, the missingness of variables is related to the characteristics of observed variables. For example, employees with higher education level are more likely to receive higher starting salary. In other words, the missing salary information is related to the observed education level, confirming that the data are not MCAR. Because no additional information indicates the NMAR property, we should be fairly comfortable to assume MAR for the OPM data. 2.5 Addressing Missing Data The loss of information from missing data would produce bias and impact the robustness of statistical modeling and inference. To address this problem, it is necessary to impute the missing data. In the next section, we would explore various imputation methods and strategies depending on the structure and the nature of the missing data. "],
["3-imputation-of-missing-data.html", "Chapter 3 Imputation of Missing Data 3.1 Overview of Multiple Imputation 3.2 Specifying Predictive Conditional Distribution - the CART method 3.3 Improving Computational Efficiency 3.4 Imputation Results and Posterior Predictive Checks", " Chapter 3 Imputation of Missing Data 3.1 Overview of Multiple Imputation Multiple Imputation (MI) is a flexible approach for researchers to address the problem of missing data. The approach of Multivariate Imputation by Chained Equation (MICE), where multiple imputed datasets are created through drawing samples sequentially from predictive conditional distribution, would be applied to generate the completed datasets. The methods for carrying out multiple imputation involve (1) Fill in the missing columns through drawing values from predictive conditional distribution to produce \\(m\\) completed datasets (2) For each completed dataset, conduct analysis for parameters of interest (3) Combine individual analysis to form final results. (Little &amp; Rubin, 2014) Currently, different methods exist for specifying predictive conditional distributions. We would explore the suitability of each method and select the best approach. Multivariate Imputation by Chained Equations (MICE) To generate \\(m\\) complete datasets, we would apply Multivariate Imputation by Chained Equations (MICE). MICE is one of the most popular approach for imputing missing data. It provides flexible imputation results and can handle both continuous and categorical data. The implementations of MICE involve Assume we have an \\(n\\)x\\(k\\) data matrix \\(Y\\), where \\(Y_1, Y_2, .., Y_j\\) are completely observed and \\(Y_{j+1}, Y_{j+2}, ..., Y_k\\) are partially observed. Step 1 For \\(i = j+1, ... , k,\\), fill in initial missing values of \\(Y_i\\) through draws from predictive distribution conditional on \\(Y_1, Y_2, ..., Y_j\\). Step 2 (a) For \\(i = j+1, ... , k,\\), construct a predictive distribution fully conditional on \\(Y_{-i} = Y_1, Y_2, ... , Y_{i-1}, Y_{i+1}, ... , Y_k\\). (b) Draw values from the conditional distribution \\(Y_i|Y_{-i}\\) and update the original missing values of column \\(Y_i\\). Step 3 Perform step 2 \\(l\\) times. Step 4 Perform step 1-3 \\(m\\) times. Since the robustness of MICE is highly dependent on the predictive conditional distribution, one of the strategy to improve the imputations is to include “auxiliary variable” that are related to the missingness but not part of the covariates. Indeed, the inclusion of “auxiliary variable” can make the MAR assumption more reasonable. (Collins, Schafer, &amp; Kam, 2001) In the OPM data, variables such as pay plan and step rate are not of interest to the final analysis, but they provide information on the missingness of salary and grade. Another auxiliary variable we include is salary from working year 11 to 15. Though we are only interested in the rate of change in salary between working year 1 and 10, salary from working year 11 to 15 can help predict past salary information. 3.2 Specifying Predictive Conditional Distribution - the CART method In the practice of MICE, one of the most common models for specifying predictive conditional distribution is Generalized Linear Models (GLMs). GLMs such as multiple linear regressions are flexible parametric models, and usually produce consistent imputation results. However, if the data to be imputed contain hundreds of variables, GLMs might be too simple to capture the true distribution. For example, relationships among variables might be interactive and non-linear. Specifying parametric models for data with great complexity is therefore inappropriate. (Burgette &amp; Reiter, 2010) Currently, the OPM data contains 65 variables, and each categorical variable has various levels. Since non-linear relationships might exist among multiple variables and levels, specifying the standard GLMs on the conditional distribution would lead to biased parameter estimates and produce inconsistent results. To address this challenge, non-parametric model is more appropriate; specifically, Classification and Regression Trees (CART) would be used to impute missing data. The CART algorithm performs binary splits of the predictors recursively to approximate the conditional distribution of a univariate outcome. The partitions are found if the subsets of units have relatively homogeneous outcomes. The leaf would be reached after multiple partitions, with values in each leaf representing the conditional distribution of the outcome. If the outcome variable is categorical, Classification Tree would be adopted; on the other hand, Regression Tree would be implemented if the outcome variable is continuous. For its application in MICE, we would use CART to derive the conditional distribution for each \\(Y_i\\) on the completely observed variables in step 1 and each \\(Y_i\\) given \\(Y_{-i}\\) in step 2. (Burgette &amp; Reiter, 2010) (Doove, Van Buuren, &amp; Dusseldorp, 2014) Though one of the disadvantages of the CART method is its difficulty for model interpretations when the number of variables is high, it should not be our major concern because the goal for adopting CART method is to plausibly impute the missing data. Indeed, the application of non-parametric CART models in MICE can result in “more reliable inferences compared with naive applications of MICE”. (Burgette &amp; Reiter, 2010) Add an example of CART Add why choose not to purn the tree Specifiy minimum heterogeneity (cp values or reduction in gini index) 3.3 Improving Computational Efficiency The CART method is computationally efficient if predictors to be split are continuous variables. Specifically, because continuous data will be sorted in ascending order before partitions, it reduces the computational complexity. On the other hand, if predictors to be split are categorical variables, the CART method might encounter computational difficulties when the number of levels is large. For example, if a categorical variable has n levels, the CART method would examine every possible splits, which results to \\(2^{n}\\) possible partitions. Indeed, the grade categorical variables in the OPM data has more than 20 levels, which means there are more than \\(2^{20} \\approx 1\\) million possible partitions. One solution to increase the computational efficiency of the CART imputation method is to reduce the number of levels for categorical variables. For example, the number of levels for variable pay plan is reduced from 173 categories into 7 categories. The OPM defines pay plan as “a two-digit alphabetical code used to identify Federal civilian pay systems”. (Office of Personal Management (OPM), n.d.) The most common pay plan in the OPM data is the General Schedule pay system, which covers around 78 percent of white-collar Federal employees. Employees who have unique occupations or serve for particular agency are covered by other pay plans. For example, the AL pay plan applies to administrative law judges, and SV refers to pay plan in the Transportation Security Administration. Since some of the pay plan codes are applicable to relatively small subset of population, we decide to merge pay plan from 173 categories into 7 categories. The summary of the simplified pay plan is shown in the table below. Abbreviated Pay Plan Type Codes General Schedule GS, GM Non General Schedule AD, ES, SV, VN, Others Another strategy used to increase the computational efficiency for MICE is through applying parallel computing technique on Step 4 of the MICE. The implementation of the parallel computing includes: Assume we want to impute \\(m\\) completed datasets with \\(n\\) cores. If (\\(m \\leq n\\)) allocate \\(m\\) cores conduct Step 1 to Step 3 once for each core in parallel else allocate \\(n\\) cores conduct Step 1 to Step 3 \\(\\lfloor{\\frac{n}{m}}\\rfloor\\) times for each core in parallel 3.4 Imputation Results and Posterior Predictive Checks 12 completed datasets are generated from the imputation model. Since the validity of the imputed datasets depends on the use of an appropriate imputation model, it is important to check whether the imputation model yields reasonable results. Specifically, posterior predictive checks (PPC) would be adopted to assess imputation model adequacy. PPC is a Bayesian model checking technique designed to investigate the potential model inadequacy between imputed and replicated datasets. Though our imputation model is not fully Bayesian, PPC could still be applied to measure the predictive differences between imputed and replicated data. (citation) Denote \\(Y = (Y_{1}, Y_{2}) = ((Y_{1,obs}, Y_{1,mis}), Y_{2}))\\), where \\(Y_{1}\\) is partially observed and \\(Y_{2}\\) is completely observed. To generate replicated data \\(Y_{com}^{rep}\\), we need to (1) create duplicates of \\((Y_{1}, Y_{2})\\) (2) set duplicated \\(Y_{1}\\) as completely missing (3) combine \\(((Y_{1,obs}, Y_{1,mis}), Y_{2})\\) and \\((Y_{com}^{rep}, Y_{2})\\) to form concatenated dataset (4) re-impute concatenated dataset with original imputation model. Figure 3.1 shows the re-imputation process. (citation) Since our parameter of interest is the relationship between year 1 and year 10 salary, we compare the distribution of these variables between imputed and replicated datasets. If the distribution of these two variables are similar between imputed and replicated datasets, then we can conclude that the imputation model provides good fit to the data. Figure 3.1: Generate replicated dataset Two different methods are used to generate replicated dataset. First, conduct re-imputation by setting duplicated \\(Y_{1}\\) (variables with missing values) as completely missing. Second, conduct re-imputation by only setting salary at working year 1 and 10 in duplicated \\(Y_{1}\\) as completely missing. The distribution between imputed and replicated dataset is shown by Figure 3.2 for the first method, and Figure 3.3 for the second method. The first method indicates that our imputation model is not a good fit to the data. However, this result is generally expected because the imputed values of year 1 and year 10 salary are highly dependent on other partially missing variables. The second method provides a better model diagnostic. The distribution between imputed and replicated datasets are similar, which implies that our imputation model provides good fit to the data. Figure 3.2: Method 1 Figure 3.3: Method 2 "],
["4-modeling-of-imputed-dataset.html", "Chapter 4 Modeling of Imputed Dataset 4.1 Outcome Variable and Selection of Covariates 4.2 Exploratory Data Analysis", " Chapter 4 Modeling of Imputed Dataset After checking the robustness of the imputation model, we conduct exploratory data analysis and model fitting based on one imputed dataset. The combined analysis and inference of 12 imputed datasets will be the focus of next chapter. 4.1 Outcome Variable and Selection of Covariates Outcome Variable The outcome variable of the OPM data is Promoted. One denotes an employee was promoted into the SES position after working year 10, and zero denotes otherwise. There are 482 employees promoted into the SES positions out of 34,120 total employees. *why we only select GS &amp; GM pay plan Covariates The OPM data consist of detailed information of federal employees, but some are unrelated to the goal of the study. Based on past social science research on the selection of high-level executives within both private and public sectors, we logically choose variables pertaining to our questions of interests as covariates. First, Gender could be a potential predictor since past studies have shown that gender plays an important role in the promotion of high-level executive positions. For example, the glass ceiling phenomenon, the phenomenon that keeps women from reaching the top level of organizations, exists in both public and private sectors. (Powell &amp; Butterfield, 1994) Second, Race and Education Level are important predictors for federal employees’ salary information (Barrientos et al., 2017), and could possibly impact the promotion process of the SES positions. Therefore, Race and Education Level should be included as covariates. Third, employees with the SES position need to build coalitions within and outside the organizations. We can extrapolate that employees who had experiences working in various government agencies might possess this competency. Department Switch, an indicator variable of whether an employee switched department between working year 1 to working year 10, could be a critical predictor. Fourth, senior executives need to have the abilities to lead people and make strategic changes. Variables such as Occupational Category and Supervisory Status might provide useful information. Lastly, the selection criteria of the SES position depend on an employee’s performance at work. There is a formal appraisal system in the OPM, but such system was not established until 1996. Given the timeframe of our population (employees starting between 1978 and 1997), including this variable is not appropriate. To address this problem, we decide to include Salary and Grade at working year 10 because these variables could potentially indicate an employee’s mid-career performance. Furthermore, we create covariate Change in Pay Rate, which specifies an employee’s rate of change in salary between working year 1 and working year 10. Particularly, employees with higher rate of change in salary would generally indicate better work performance. To sum up, our analysis approach is to inspect not only fixed variables independent of time such as race, gender, and education levels but also variables indicative of an employee’s mid-career performance such as salary and grade achieved at working year 10. Assumptions The number of SES positions is limited in each agency and potential candidates tend to get promoted at different year. This means that the promotion criteria might vary among years. However, given the rarity of the SES positions, one key assumption we have to make is that the covariates selected are general enough to capture the promotion criteria despite time differences. Furthermore, we adjust salary in terms of 2011 inflation rate to make sure variables dependent on time are compared on the same basis. 4.2 Exploratory Data Analysis To examine the relationship between outcome variable and predictors, we apply two different strategies for categorical and continuous predictors. First, for categorical predictors, we look at the percentages of ones in outcome variable for each level. If a categorical predictor has many levels but the proportion of ones in outcome variable for certain levels is too small, we consider regrouping to reduce levels. Second, for continuous predictor, we first break predictor into \\(n\\) equally sized, ordered groups, and compute the percentage of ones in outcome variable for each group. We then visualize the patterns between groups, and explore the needs for transformation. Gender (Categorical) Variable Gender consists of 2 levels - Male and Female (M,F). There are more females than males, but each gender has similar proportion of ones. Gender Gender population (%) promoted (%) Male (M) 39.62 1.39 Female (F) 60.38 1.76 Race (Categorical) Variable Race consists of 6 levels - Hispanic or Latino (1), American Indian or Alaska Native (2), Asian (3), Black or African American (4), Native Hawaiian or Other Pacific Islander (5), and White (6). Because there are significantly less people with race level 1 - 5 is than people with race level 6, race is regrouped into two levels - Non-white (0), and White (1). Race before regrouping Race population (%) promoted (%) Hispanic/Latino (1) 7.65 0.91 American Indian/Alaska Native (2) 1.7 1.07 Asian (3) 4.46 0.82 Black/African American (4) 12.43 1.38 Native Hawaiian/Other Pacific Islander (5) 0.05 0 White (6) 73.7 1.79 Race after regrouping Race population (%) promoted (%) Non-white (0) 26.3 1.13 White (1) 73.7 1.79 Education Level (Categorical) Variable Education Level consists of 7 levels - High School Degree or less (0), More than High School, No Bachelor’s (1), Bachelor’s (2), Master’s (3), Professional Degree (4), Advanced Certification (5), and PhD (6). Because certain education levels have relatively small population size, it is regrouped from 7 to 5 levels based on each level’s characteristics. Specifically, employees without Bachelor’s degree (level 0 and level 1) are combined into one group, and employees with Professional Degree and Advanced Certification (Level 4 and 5) are combined into another group. Education Level before regrouping Education Level population (%) promoted (%) High School Degree or less (0) 8.5 0.38 More than High School, No Bachelor’s (1) 18.57 0.59 Bachelor’s (2) 40.43 1.39 Master’s (3) 22.33 2.31 Professional Degree (4) 5.05 4.77 Advanced Certification (5) 0.25 1.45 PhD (6) 4.79 3.05 Education Level after regrouping Education Level population (%) promoted (%) Less than Bachelor’s (A) 27.14 0.53 Bachelor’s (B) 40.44 1.39 Master’s (C) 22.33 2.31 Professional Degree &amp; Advanced Certification (D) 5.3 4.62 PhD (E) 4.79 3.05 Department Switch (Categorical) Variable Department Switch indicates whether employees switch department between working year 1 and working year 10. The majority did not switch department, but each group has similar proportion of people promoted into the SES position regardless of department switch. Department Switch Department Switch population (%) promoted (%) No Switch 91.17 1.6 Switch 8.83 1.7 Occupational Category (Categorical) Variable Occupational Category consists of 3 levels - Administrative (A), Professional (P), and Other White Collar (O). For occupational category Other (O), though the population size of this group is small, we do not exclude employees from this occupational category because the number of ones among total population is already small. Occupational Category Occupational Category population (%) promoted (%) Administrative (A) 58.06 1.71 Professional (P) 38.97 1.56 Other (O) 2.97 0.49 Supervisory Status (Categorical) Variable Supervisory Status indicates whether employees hold supervisory position at working year 10. People with supervisory positions have higher proportion of ones than people without supervisory positions. Supervisory Status Supervisory Status population (%) promoted (%) Supervisor 14.34 5.69 Non-supervisor 85.66 0.93 Year 10 Grade (Categorical) Variable Year 10 Grade consists of 7 levels - grade 9 - 15. Because the proportion of ones for grade 9 to 12 is relatively small compared to that for grade 13 to 15, year 10 grade is regrouped into two levels - 0 (Year 10 grade 9 to 12), and 1 (Year 10 grade 13 to 15). Year 10 Grade before regrouping Year 10 Grade population (%) promoted (%) 9 16.46 0.11 10 2.44 0.30 11 22.88 0.26 12 24.35 0.75 13 20.81 1.69 14 9.66 4.77 15 3.39 15.73 Year 10 Grade after regrouping Year 10 Grade population (%) promoted (%) 0 66.13 0.4 1 33.87 3.97 Year 10 Salary (Continuous) Variable Year 10 Salary specifies employees’ salary at working year 10. Based on OPM’s 2011 General Schedule pay table, employees with grade 9 has minimum salary of 41,563, and employees with grade 15 has maximum salary of 129,517. Due to random noises produced by the imputation model, the imputed datasets consist of grade 9 employees with salary less than 41,563, and grade 15 employees with salary greater than 129,517. Since these outliers account for less than 0.1% of the total observations for each imputed dataset, no concerns on the robustness of the analysis are raised. In addition, combining multiply-imputed datasets to form final analysis could help averaging out the random noises. The visualization graph below is produced based on the strategies mentioned before (Figure 4.1). The x-axis denotes 10 equally sized group, with each group represents certain salary ranges. (Year 10 Salary Table). The y-axis denotes the percentage of ones in each group. In general, employees with higher salary have higher percentage of ones. Specifically, group 1 to 8 have percentage of ones less than 2 %, whereas group 9 and 10 have percentage of ones larger than 2 %. The flat curve between group 1 and group 8 and the spike in group 9 and 10 indicate that the relationship between outcome variable and year 10 salary predictor is non-linear. To capture the non-linear relationship, we consider various transformation such as quadratic polynomial transformation. However, we find that the application of semi-parametric piecewise spline function is the most effective in modeling this continuous predictor. The detailed descriptions of spline modeling approach will be mentioned in the next section. Figure 4.1: Year 10 Salary Binned Plot Year 10 Salary Table Group Salary Range % promoted 1 [25740,47744) 0.18 2 [47744,52653) 0.22 3 [52653,56801) 0.18 4 [56801,61726) 0.4 5 [61726,66339) 0.66 6 [66339,71136) 0.7 7 [71136,77180) 1.3 8 [77180,82160) 1.43 9 [82160,93591) 3.65 10 [93591,149505) 7.39 Because the baseline of year 10 grade is determined by grade 13, year 10 salary is centered on the mean salary at grade 13 from OPM’s 2011 pay table (the mean is around $82,425). Year 10 salary is also scaled by $10,000 for interpretation purpose. Specifically, denote \\(x_{i}\\) as employee \\(i\\)’s year 10 salary, \\(scale(x_{i}) = \\dfrac{x_{i} - 82,425}{10,000}\\). Change in Pay Rate (Categorical) Variable Change in Pay Rate specifies the percentage change in salary between working year 1 and working year 10. The construction of the visualization graph for change in pay rate is similar to that for year 10 salary. (Figure 4.2) The x-axis denotes 10 equally sized group, with each group represents certain change in pay rate. (Change in Pay Rate Table). The y-axis denotes the percentage of ones in each group. Though we believe that higher percentage of change in salary might indicate better performance at work, it is not reflected in the promotion of the SES position. Regardless of change rate, the graph does not indicate particular trend since the proportion of ones fluctuates among groups. This means that Change in Pay Rate probably doesn’t provide predictive power if treated as continuous variable. Figure 4.2: Change in Pay Rate Binned Plot Year 10 Pay Rate Change before regrouping Group % Change Range % promoted 1 [-10.3,40.4) 1.39 2 [40.4,57.2) 1.79 3 [57.2,69.8) 1.24 4 [69.8,81.1) 0.10 5 [81.1,92.5) 1.35 6 [92.5,105.5) 1.39 7 [105.5,120.5) 1.57 8 [120.5,140.7) 1.83 9 [140.7,174.8) 1.87 10 174.8+ 2.71 Year 10 Pay Rate Change after regrouping Group % Change Range promoted (%) Change1 [-10.34,62) 1.51 Change2 [62,160) 1.42 Change3 160+ 2.66 To address the problem, we decide to model pay rate as a categorical variable with 3 levels. The first level consists of employees with rate changes below 62% (equals to around 5% change per year). This pay rate change range falls within the regular rate change of the federal government. The second level consists of employees with rate change between 62% and 160% (equals to around 5 - 10% change per year). This rate change range is higher than the regular rate change, indicating that employees with this rate change level might perform better than employees with regular rate change level. The third level consists of employees with rate changes above 160%. This rate change is significantly higher than the regular change rate. However, some of the very high rate change values are sensitive to the imputation models since more than 80% of the rate change data is missing. "],
["5-model-fitting.html", "Chapter 5 Model Fitting 5.1 Spline Logistic Regression 5.2 Frequentist - Maximum Likelihood Approach 5.3 Bayesian - Posterior Distribution 5.4 Final Model", " Chapter 5 Model Fitting According to the results from exploratory data analysis, we fit a model based on one imputed dataset, where model coefficients are computed from two approaches - Frequentist’s Maximum Likelihood Estimation and Bayesian’s Posterior Distribution. 5.1 Spline Logistic Regression In Generalized Linear Models (GLMs), the coefficients of predictors on univariate outcome variable Y is usually linear. However, the binnedplot of predictor year 10 salary shows that the relationship between outcome variable and year 10 salary is non-linear. In order to capture the non-linear relationship, one common strategy is to incorporate smoothing techniques such as the application of spline function into the GLMs. A semi-parametric spline logistic regression is therefore used to model the data. To recap the relationship between year 10 salary and outcome variable, the proportion of ones below certain salary level is relatively flat, whereas the proportion of ones above certain salary level increases significantly. (Figure 5.1) This indicates that the coefficient slopes should be different for salary above and below certain level, which can be modeled by a spline function. Figure 5.1: Year 10 Salary Binned Plot A spline of degree D is a continuous function formed by connecting polynomial segments. The points where the segments connect are called the knots of the spline. In general, a spline of degree D associated with a knot \\(\\xi_{k}\\) takes the form: \\[ (x-\\xi_{k})_{+}^{D}= \\begin{cases} 0, &amp; x &lt; \\xi_{k}\\\\ (x-\\xi_{k})^{D}, &amp; x \\geq \\xi_{k} \\end{cases} \\] Because the shapes of both segments (blue and red segments in the binned plot) are close to linear, the degree of the spline function is 1. A knot is chosen as the cut point between the two segments, which takes the value of $77,100. (Since year 10 salary is centered and scaled, this cut point should be \\(\\dfrac{77,180 - 82,425}{10,000} = -0.5425\\).) Denote \\(x\\) as the year 10 salary after transformation. The equation for the piecewise linear spline is \\[ \\begin{aligned} y &amp; = \\beta_{0} + \\beta_{1}x + \\beta_{2}(x - (-0.5425))_{+} \\\\ &amp; = \\beta_{0} + \\beta_{1}x + \\beta_{2}(x + 0.5425)(I[x \\geq -0.5425]) \\end{aligned} \\] If year 10 salary is below the cut point, the coefficient \\(\\beta_{2}\\) would be equal to 0. On the other hand, if year 10 salary is above the cut point, the coefficient \\(\\beta_{2}\\) would help capture the difference in slopes. To sum up, we can rewrite the above equation as \\[ y = \\begin{cases} \\beta_{0} + \\beta_{1}x, &amp; x &lt; -0.5425\\\\ \\beta_{0} + \\beta_{1}x + \\beta_{2}(x + 0.5425)(I[x \\geq -0.5425]), &amp; x \\geq -0.5425 \\end{cases} \\] Baseline Other than year 10 salary, the rest of the covariates are categorical variables. Given that the proportion of ones in outcome variable is small, it is important to select reasonable baseline for each categorical variable. For variable Gender, we would like to learn whether women were put in disadvantages during promotion, so male is the baseline. For variable Race, since the population size for white is the largest, white is the baseline. For variable Education Level, Bachelor’s degree is the baseline because it is the most common degree federal employees earned. For variable Department Switch, switch is the baseline. For variable Occupational Category, Professional is the baseline. For variable Supervisory Status, supervisor is the baseline. For variable Year 10 Grade, grade above 13 is the baseline. For variable Change in Pay Rate, change2 (annual rate change between 5-10%) is the baseline. Model Form (Full Model) To sum up, the model takes the following form. \\[ \\begin{aligned} logit(p) &amp; = \\beta_{0}+ \\beta_{1}\\text{Female} + \\beta_{2}\\text{OccA} + \\beta_{3}\\text{OccO} + \\beta_{4}\\text{EducA} + \\beta_{5}\\text{EducC} + \\beta_{6}\\text{EducD} \\\\ &amp; + \\beta_{7}\\text{EducE} + \\beta_{8}\\text{Non-White} + \\beta_{9}\\text{NoSwitch} + \\beta_{10}\\text{Non-Supervisor} + \\beta_{11}\\text{Grade0} \\\\ &amp; + \\beta_{12}\\text{Salary} + \\beta_{13}(\\text{Salary} + 0.5425)*I[\\text{Salary} \\geq 0.5425] + \\beta_{14}\\text{Change1} + \\beta_{15}\\text{Change3} \\end{aligned} \\] 5.2 Frequentist - Maximum Likelihood Approach Model Coefficients In a frequentist setting, the estimation of model coefficients are computed through maximum likelihood approach. The table shows the estimate, standard error, p-value of each coefficient. Coefficient Estimate Std. Error p-value (Intercept) (\\(\\beta_{0}\\)) -5.589 0.706 0.0000000000000024 Female (\\(\\beta_{1}\\)) -0.026 0.106 0.80787 OccA (\\(\\beta_{2}\\)) 0.766 0.122 0.0000000003766811 OccO (\\(\\beta_{3}\\)) 1.032 0.539 0.05571 EducA (\\(\\beta_{4}\\)) -0.742 0.188 0.0000770642309893 EducC (\\(\\beta_{5}\\)) 0.166 0.125 0.18347 EducD (\\(\\beta_{6}\\)) 0.240 0.179 0.17915 EducE (\\(\\beta_{7}\\)) 0.005 0.207 0.98274 Non-White (\\(\\beta_{8}\\)) -0.098 0.128 0.44430 No_Switch (\\(\\beta_{9}\\)) -0.067 0.179 0.69805 Non-Supervisor (\\(\\beta_{10}\\)) -1.063 0.106 0.0000000000000002 Grade0 (\\(\\beta_{11}\\)) -0.705 0.224 0.00167 Salary (\\(\\beta_{12}\\)) 2.067 0.672 0.00210 (Salary + 0.5425) (\\(\\beta_{13}\\)) 5.248 0.706 0.0000000000001042 Change1 (\\(\\beta_{14}\\)) -0.441 0.132 0.00086 Change3 (\\(\\beta_{15}\\)) 0.293 0.126 0.01967 Gender (\\(\\beta_{1}\\)), Race (\\(\\beta_{8}\\)), and Switch (\\(\\beta_{9}\\)) are not significant in predicting promotion outcomes, with their p-values much greater than 0.05. We further conduct a change in deviance test to better understand the fit of those variables. Specifically, denote \\(D_{0}\\) as the deviance of reduced model (without Gender, Race, and Switch), and \\(D_{1}\\) as the deviance of full model (original model). For large sample size, the difference between \\(D_{0}\\) and \\(D_{1}\\) has a chi-square distribution with degrees of freedom equal to the difference in the number of parameters estimated. The change in deviance test yields a p-value of 0.846, indicating that the inclusion of variable Gender, Race, and Switch does not provide a better fit to the data. Therefore, the reduced model is a better model. Model Diagnostic Constant variance and normality of residuals are not assumptions for logistic regression. To check if function of predictor is well specified, binned residuals technique is applied to reduced model. In order to produce binned residuals, we first compute raw residuals for fitted logistic regression model, and order observations by values of predicted probabilities from the fitted regression. Second, for continuous predictor, we form \\(\\sqrt{27346} \\approx 165\\) equally sized, ordered bins using ordered data, and compute average residual in each bin. For categorical predictor, we compute the average residual in each level. Lastly, we plot average residual versus average predicted probability for each bin, and find specific patterns that might yield problems. According to binned residuals plot (Figure 5.2), the average residuals are close to 0 for scaled salary less than 0 (corresponds to $82,425), but tend to have more fluctuation for scaled salary greater than 0. The fluctuation is caused by small proportion of ones in outcome variable and shouldn’t be of concern. For categorical variable, because the number of level is limited and the prediction would yield 0 (not promoted) majority of the time, the average residuals for each bin are small. (table) In general, no extreme residuals are observed, and we can conclude that the model provides reasonable fit to the data. Figure 5.2: Residuals Binned Plot 5.3 Bayesian - Posterior Distribution In addition to estimating the model coefficients through maximum likelihood approach, we further fit a Bayesian Logistics Regression model to verify our results. Bayesian analysis requires the specification of the prior distributions for both the intercept and coefficients. Prior to seeing the data, we assume that the intercept (\\(\\beta_{0}\\)) and the coefficients of the predictors (\\(\\beta = \\beta_{1}, ..., \\beta_{j}\\)) have normal distribution with mean 0 and variance 5 - that \\(\\beta_{0}\\) and \\(\\beta\\) are as likely to be positive as they are to be negative but unlikely to be far away from zero. After observing the data, the likelihood of each observation can be modeled as a binomial distribution \\(p(x_{i},y_{i}|\\beta_{0},\\beta) = Binomial(1, \\pi_{i})\\) for \\(i = 1,...,n\\); \\(\\pi_{i}\\) is the probability of getting promoted, where \\(\\pi_{i} = logit^{-1}(\\beta_{0} + \\beta x_{i}) = \\dfrac{exp(\\beta_{0} + \\beta x_{i})}{1 +exp(\\beta_{0} + \\beta x_{i}) }\\). The posterior distribution is proportional to the product of the priors and the likelihood distribution. To sum up, the posterior distribution is derived as below. Prior Distribution \\[ \\begin{aligned} f(\\beta_{0}) &amp;= N(0,5)\\\\ f(\\beta_{k}) &amp;= N(0,5), k = 1,...,15 \\\\ \\end{aligned} \\] Likelihood \\[ \\begin{aligned} p(X,Y|\\beta_{0},\\beta) &amp; = \\prod_{i=1}^{n} p(x_{i},y_{i}|\\beta_{0},\\beta) \\\\ &amp; = \\prod_{i=1}^{n} {1 \\choose y_{i}} (\\dfrac{exp(\\beta_{0} + \\beta x_{i})}{1 +exp(\\beta_{0} + \\beta x_{i})})^{y_{i}}(\\dfrac{1}{1 +exp(\\beta_{0} + \\beta x_{i})})^{1-y_{i}}\\\\ &amp; = {n \\choose \\sum y_{i}} (\\prod_{i=1}^{n}\\dfrac{exp(\\beta_{0} + \\beta x_{i})}{1 +exp(\\beta_{0} + \\beta x_{i})})^{\\sum y_{i}}(\\prod_{i=1}^{n}\\dfrac{1}{1 +exp(\\beta_{0} + \\beta x_{i})})^{n-\\sum y_{i}} \\\\ &amp; = {n \\choose \\sum y_{i}} (\\prod_{i=1}^{n} logit^{-1}(\\beta_{0} + \\beta x_{i}))^{\\sum y_{i}}(\\prod_{i=1}^{n}(1- logit^{-1}(\\beta_{0} + \\beta x_{i})))^{n-\\sum y_{i}} \\\\ &amp; \\propto (\\prod_{i=1}^{n} logit^{-1}(\\beta_{0} + \\beta x_{i}))^{\\sum y_{i}}(\\prod_{i=1}^{n}(1- logit^{-1}(\\beta_{0} + \\beta x_{i})))^{n-\\sum y_{i}} \\\\ \\end{aligned} \\] Posterior Distribution \\[ \\begin{aligned} f(\\beta_{0},\\beta|X,Y) &amp; = f(\\beta_{0}){\\prod_{k=1}^{j} f(\\beta_k)} f(X,Y|\\beta_{0},\\beta) \\\\ &amp; \\propto f(\\beta_{0}) {\\prod_{k=1}^{j} f(\\beta_k)} (\\prod_{i=1}^{n} logit^{-1}(\\beta_{0} + \\beta x_{i}))^{\\sum y_{i}}(\\prod_{i=1}^{n}(1- logit^{-1}(\\beta_{0} + \\beta x_{i})))^{n-\\sum y_{i}} \\end{aligned} \\] The 95% posterior interval graph (Figure 5.3) are produced by fitting a Bayesian logistic regression model on all 15 predictors. The median of predictors Gender, Race, and Switch in the graph are close to 0, indicating that these variables do not provide predictive power on the outcome variable. The Bayesian model yields similar results to maximum likelihood approach, where the change in deviance test also suggests that variable Gender, Race, and Switch are not significant. Figure 5.3: Bayesian Full Model 5.4 Final Model The results from both Frequentist and Bayesian suggest that the reduced model is a better model than the full model, which takes the following form: \\[ \\begin{aligned} logit(p) &amp; = \\beta_{0} + \\beta_{1}\\text{OccA} + \\beta_{2}\\text{OccO} + \\beta_{3}\\text{EducA} + \\beta_{4}\\text{EducC} + \\beta_{5}\\text{EducD} \\\\ &amp; + \\beta_{6}\\text{EducE} + \\beta_{7}\\text{Non-Supervisor} + \\beta_{8}\\text{Grade0} \\\\ &amp; + \\beta_{9}\\text{Salary} + \\beta_{10}(\\text{Salary} + 0.5425)*I[\\text{Salary} \\geq 0.5425] + \\beta_{11}\\text{Change1} + \\beta_{12}\\text{Change3} \\end{aligned} \\] In the next chapter, we would combine model results of 12 imputed datasets, and conduct inference based on the pooled model coefficients. "],
["6-pooled-analysis.html", "Chapter 6 Pooled Analysis 6.1 Pooled Results 6.2 Inference", " Chapter 6 Pooled Analysis 6.1 Pooled Results In order to conduct inference on regression slopes \\(\\beta\\), we combine model results from 12 imputed datasets. For Frequentist model, the combined results are obtained through (1) averaging out the estimated regression coefficients of each completed dataset (2) accounting for both within and across datasets variances. For Bayesian model, the combined results are obtained through summarizing the mixture draws from posterior distribution. 6.1.1 Frequentist Model For each completed dataset \\(j\\) (\\(j = 1,...,12\\)) and each regression coefficient \\(\\beta_{ij}\\) (\\(i = 0,...,12\\)), let \\(b_{ij}\\) be the estimator of \\(\\beta_{ij}\\) from \\(j_{th}\\) dataset, and let \\(u_{ij}\\) be the estimator of the variance of \\(\\beta_{ij}\\) from \\(j_{th}\\) dataset. First, the estimate of the model coefficient \\(\\overline{b_{i}}\\) is obtained by computing the average of each dataset’s estimated slope. Second, the within-dataset variance \\(\\overline{u_{i}}\\) is obtained by computing the average of each dataset’s estimated slope variance. Lastly, the across-datasets variance \\(q_{i}\\) is obtained by computing the average of the variance of the slope. \\[ \\begin{aligned} &amp; \\overline{b_{i}} = \\sum_{j=1}^{12}b_{ij}/12 \\\\ &amp; \\overline{u_{i}} = \\sum_{j=1}^{12}u_{ij}/12 \\\\ &amp; q_{i} = \\sum_{j=1}^{12}(b_{ij} -\\overline{b_{ij}})/(12-1) \\\\ \\end{aligned} \\] With average estimated regression coefficient (\\(\\overline{b_{i}}\\)), within-dataset variance (\\(\\overline{u_{i}}\\)), and across-datasets variance (\\(q_{i}\\)), the point estimate of \\(\\beta_{i}\\) is \\(\\overline{b_{i}}\\), and its variance is estimated by \\(T_{i} = (1+1/12)q_{i}+\\overline{u_{i}}\\), An approximate 95% confidence interval is \\(\\overline{b_{i}} \\pm 1.96\\sqrt{T_{i}}\\). The table shows the pooled estimated slope, standard error, and 95% confidence interval of each regression coefficient. Combined Coefficient Estimate, Standard Error, and 95% CI. (Frequentist’s Model) Coefficient Estimate Std. Error 95% CI. Intercept -5.732 0.625 [-6.556, -4.909] OccA 0.754 0.015 [0.722, 0.786] OccC 0.986 0.295 [0.849, 1.123] EducA -0.757 0.035 [-0.787, -0.727] EducC 0.150 0.016 [0.119, 0.181] EducD 0.265 0.032 [0.208, 0.321] EducE -0.018 0.044 [-0.094, 0.057] Non-Supervisor -1.045 0.012 [-1.099, -0.990] Grade0 -0.698 0.059 [-0.894, -0.502] Salary 2.145 0.613 [1.323, 2.966] (Salary + 0.5425) 5.516 0.629 [4.771, 6.261] Change1 -0.355 0.026 [-0.540, -0.170] Change3 0.224 0.025 [0.056, 0.393] 6.1.2 Bayesian Model For Bayesian model, instead of averaging out the estimated regression coefficients, the pooled results are obtained through applying the approach proposed by Zhou and Reiter (2010). For each completed dataset \\(l = 1,...,m\\) and parameter of interest \\(Q\\), denote \\(Q^{(l)}\\) as the MCMC draws from posterior distribution. First, simulate \\(J\\) values of posterior draws (where \\(J\\) is large) from each \\(Q^{(l)}\\), with its distribution denoted as \\(\\hat{f}(Q^{(l)})\\). Second, mix all \\(\\hat{f}(Q^{(l)})\\) to form \\(\\hat{f}(Q^{(all)})\\). Third, sort total number of \\(m*J\\) draws from \\(\\hat{f}(Q^{(all)})\\), where the estimates of 95% posterior interval, posterior median, and other statistics can be obtained from the mixed posterior draws. (citation) The pooled estimated slope, standard error, and 95% credible interval are generated through specifying \\(J = 4000\\) to create a total number of \\(12*4000 = 48000\\) draws. Combined Coefficient Estimate, Standard Error, and 95% CI. (Bayesian Model) Coefficient Estimate Std. Error 95% CI. Intercept -5.753 0.77 [-7.346, -4.322] OccA 0.754 0.12 [0.517, 0.993] OccC 0.834 0.56 [-0.374, 1.832] EducA -0.760 0.19 [-1.140, -0.403] EducC 0.150 0.12 [-0.094, 0.395] EducD 0.260 0.18 [-0.092, 0.606] EducE -0.028 0.21 [-0.441, 0.376] Non-Supervisor -1.045 0.11 [-1.256, -0.829] Grade0 -0.703 0.24 [-1.188, -0.249] Salary 2.159 0.76 [0.752, 3.738] (Salary + 0.5425) 5.534 0.77 [4.055, 7.086] Change1 -0.358 0.16 [-0.668, -0.062] Change3 0.220 0.15 [-0.088, 0.506] 6.1.3 Comparison between Frequentist and Bayesian Model Figure 6.1 and Figure 6.2 are used to compare the pooled resulst from Frequentist and Bayesian Model. The estimates of regression coefficients for both models are close to each other, but the pooled standard errors from Bayesian model are higher than those from Frequentist model. The greater uncertainty of Bayesian model, however, does not suggest that Frequentist model is a more ideal model. First, the posterior distribution depends on the prior parameter, and non-informative prior might not be the most ideal prior. Second, in order for pooled Bayesian model to work well, the number of imputed datasets should be large. (citation) Due to computational constraints, only 12 imputed datasets are available Figure 6.1: Frequentist Model Figure 6.2: Bayesian Model 6.2 Inference The assumption that a federal employees’s gender and race will directly and indirectly influence the promotion decisions for top management positions is proved to be invalid. Furthermore, our prior belief that an employee working at more than one government agencies would be better at building coalitions with various stakeholders is rejected. In general, the selection of the SES positions is highly dependent on (1) personal skills (indicated by variable Occupational Category and Supervisory Status) (2) education levels (indicated by variable Education Group) (3) performance at work (indicated by variable Salary, Grade, and Change) First, for employees whose occupational category are Administrative, the odds of getting promoted are multiplied by a factor of 2.13 (95% CI: 1.68 to 2.7) than employees whose occupational category are Professional, holding all else constant. This implies that analytical ability, judgment, discretion, and personal responsibility (characteristics of occupational category Administrative) might be more important than having knowledge in a specific field of science (characteristics of occupational category Professional). Furthermore, for employees who do not hold supervisory positions, the odds of getting promoted are multipled by a factor of 0.352 (95% CI: 0.285 to 0.436) than employees who hold supervisory positions, holding all else constant. Since leadership is one of the key competencies for the SES positions, employees without leadership expereinces would be put into disadvantages. Second, education level also plays an important role when it comes to promotion outcome. For employees with degrees below Bachelor’s, the odds of getting promoted is multiplied by 0.469 (95% CI: 0.455 to 0.483) compared to employees with Bachelor’s degree, holding all else constant. Furthermore, though it is expected that the odds of getting promoted would increase with higher education level, there is certain limit. Specifically, compared to employees with only Bachelor’s degrees, the odds of getting promoted increases if employees acquired Master’s and Advanced degrees but decreases if employees acquired PhD degrees. This result further confirms that having specific knowledge in a field of science might not be one of the important promotion criteria. Third, for employees with grade below 13 at workig year 10, the odds of getting promoted are multiplied by a factor of 0.495 (95% CI: 0.305 to 0.78) compared to employees with grade above 13 at working year 10, holding all else constant. This result is generally expected because when it comes to selecting potential candidates for the SES positions, employees with grade above 13 are generally given priority. The visualization graph (Figure ) below further shows the relationship between salary at working year 10 and % change in salary. "],
["references.html", "References", " References "]
]
