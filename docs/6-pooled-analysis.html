<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Modeling Federal Employees Data to Predict Promotion</title>
  <meta name="description" content="Modeling Federal Employees Data to Predict Promotion">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Modeling Federal Employees Data to Predict Promotion" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Modeling Federal Employees Data to Predict Promotion" />
  
  
  

<meta name="author" content="Chia-Rui (Jerry) Chang">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="5-model-fitting.html">
<link rel="next" href="references.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="1" data-path="1-introduction.html"><a href="1-introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="2-data.html"><a href="2-data.html"><i class="fa fa-check"></i><b>2</b> Data</a></li>
<li class="chapter" data-level="3" data-path="3-missing-data-multiple-imputation.html"><a href="3-missing-data-multiple-imputation.html"><i class="fa fa-check"></i><b>3</b> Missing Data &amp; Multiple Imputation</a><ul>
<li class="chapter" data-level="3.1" data-path="3-missing-data-multiple-imputation.html"><a href="3-missing-data-multiple-imputation.html#missing-data"><i class="fa fa-check"></i><b>3.1</b> Missing data</a></li>
<li class="chapter" data-level="3.2" data-path="3-missing-data-multiple-imputation.html"><a href="3-missing-data-multiple-imputation.html#overview-of-multiple-imputation"><i class="fa fa-check"></i><b>3.2</b> Overview of Multiple Imputation</a></li>
<li class="chapter" data-level="3.3" data-path="3-missing-data-multiple-imputation.html"><a href="3-missing-data-multiple-imputation.html#specifying-predictive-conditional-distribution---the-cart-method"><i class="fa fa-check"></i><b>3.3</b> Specifying predictive conditional distribution - the CART method</a></li>
<li class="chapter" data-level="3.4" data-path="3-missing-data-multiple-imputation.html"><a href="3-missing-data-multiple-imputation.html#improving-computational-efficiency"><i class="fa fa-check"></i><b>3.4</b> Improving computational efficiency</a></li>
<li class="chapter" data-level="3.5" data-path="3-missing-data-multiple-imputation.html"><a href="3-missing-data-multiple-imputation.html#imputation-results-and-predictive-checks"><i class="fa fa-check"></i><b>3.5</b> Imputation results and predictive checks</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-exploratory-data-analysis-eda.html"><a href="4-exploratory-data-analysis-eda.html"><i class="fa fa-check"></i><b>4</b> Exploratory Data Analysis (EDA)</a><ul>
<li class="chapter" data-level="4.1" data-path="4-exploratory-data-analysis-eda.html"><a href="4-exploratory-data-analysis-eda.html#outcome-variable-and-covariates-selection"><i class="fa fa-check"></i><b>4.1</b> Outcome variable and covariates selection</a></li>
<li class="chapter" data-level="4.2" data-path="4-exploratory-data-analysis-eda.html"><a href="4-exploratory-data-analysis-eda.html#inspection-of-each-covariate"><i class="fa fa-check"></i><b>4.2</b> Inspection of each covariate</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-model-fitting.html"><a href="5-model-fitting.html"><i class="fa fa-check"></i><b>5</b> Model Fitting</a><ul>
<li class="chapter" data-level="5.1" data-path="5-model-fitting.html"><a href="5-model-fitting.html#logistic-regression-with-piecewise-linear-spline-application"><i class="fa fa-check"></i><b>5.1</b> Logistic regression with piecewise linear spline application</a></li>
<li class="chapter" data-level="5.2" data-path="5-model-fitting.html"><a href="5-model-fitting.html#baseline"><i class="fa fa-check"></i><b>5.2</b> Baseline</a></li>
<li class="chapter" data-level="5.3" data-path="5-model-fitting.html"><a href="5-model-fitting.html#model-form"><i class="fa fa-check"></i><b>5.3</b> Model Form</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-pooled-analysis.html"><a href="6-pooled-analysis.html"><i class="fa fa-check"></i><b>6</b> Pooled Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="6-pooled-analysis.html"><a href="6-pooled-analysis.html#estimates-of-model-coefficients"><i class="fa fa-check"></i><b>6.1</b> Estimates of model coefficients</a></li>
<li class="chapter" data-level="6.2" data-path="6-pooled-analysis.html"><a href="6-pooled-analysis.html#pooled-results"><i class="fa fa-check"></i><b>6.2</b> Pooled results</a><ul>
<li class="chapter" data-level="6.2.1" data-path="6-pooled-analysis.html"><a href="6-pooled-analysis.html#frequentist-model"><i class="fa fa-check"></i><b>6.2.1</b> Frequentist model</a></li>
<li class="chapter" data-level="6.2.2" data-path="6-pooled-analysis.html"><a href="6-pooled-analysis.html#bayesian-model"><i class="fa fa-check"></i><b>6.2.2</b> Bayesian Model</a></li>
<li class="chapter" data-level="6.2.3" data-path="6-pooled-analysis.html"><a href="6-pooled-analysis.html#comparison-between-frequentist-and-bayesian-model"><i class="fa fa-check"></i><b>6.2.3</b> Comparison between Frequentist and Bayesian Model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-pooled-analysis.html"><a href="6-pooled-analysis.html#inference-based-on-frequentist-model"><i class="fa fa-check"></i><b>6.3</b> Inference based on Frequentist model</a></li>
<li class="chapter" data-level="6.4" data-path="6-pooled-analysis.html"><a href="6-pooled-analysis.html#conclusion-and-future-improvement"><i class="fa fa-check"></i><b>6.4</b> Conclusion and future improvement</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modeling Federal Employees Data to Predict Promotion</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pooled-analysis" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Pooled Analysis</h1>
<p>We estimated the model coefficients of each completed dataset and conducted model diagnostic based on one completed dataset. We then combined model results of all datasets for inference.</p>
<div id="estimates-of-model-coefficients" class="section level2">
<h2><span class="header-section-number">6.1</span> Estimates of model coefficients</h2>
<p>In a frequentist setting, estimates of model coefficients are computed through maximum likelihood estimation. In a Bayesian setting, estimates of model coefficients are computed through posterior distribution, which requires the specification of prior distributions.</p>
<p>Prior to seeing the data, we assumed that the intercept (<span class="math inline">\(\beta_{0}\)</span>) have normal distribution with mean -3 and variance 2. The coefficients of the predictors (<span class="math inline">\(\beta = \beta_{1}, ..., \beta_{17}\)</span>) have normal distribution with mean 0 and variance 5 - that <span class="math inline">\(\beta\)</span> are as likely to be positive as they are to be negative but unlikely to be far away from zero. After observing the data, we modeled the likelihood of each observation as a binomial distribution <span class="math inline">\(p(y_{i}|x_{i},\beta_{0},\beta_{1},...,\beta_{17}) = Binomial(1, \pi_{i})\)</span> for <span class="math inline">\(i = 1,...,n\)</span>; <span class="math inline">\(\pi_{i}\)</span> is the probability of getting promoted, where <span class="math inline">\(\pi_{i} = logit^{-1}(\beta_{0} + \beta \cdot x_{i}) = \dfrac{exp(\beta_{0} + \beta \cdot x_{i})}{1 +exp(\beta_{0} + \beta \cdot x_{i}) }\)</span>. The posterior distribution is proportional to the product of the priors and the likelihood distribution. To sum up, the posterior distribution is derived as below.</p>
<p><strong>Prior Distribution</strong> <span class="math display">\[
\begin{aligned}
f(\beta_{0}) &amp;= N(-3,2)\\
f(\beta_{k}) &amp;= N(0,5), k = 1,...,17 \\
\end{aligned}
\]</span></p>
<p><strong>Likelihood</strong> <span class="math display">\[
\begin{aligned}
p(Y|x^{cmp},\beta_{0},\beta) 
&amp; = \prod_{i=1}^{n} p(y_{i}|x_{i},\beta_{0},\beta) \\
&amp; = \prod_{i=1}^{n} [logit^{-1}(\beta_{0} + \beta \cdot x_{i})]^{y_{i}}[1 - logit^{-1}(\beta_{0} + \beta \cdot x_{i})]^{(1-y_{i})}\\
\end{aligned}
\]</span></p>
<p><strong>Posterior Distribution</strong> <span class="math display">\[
\begin{aligned}
f(\beta_{0},\beta|X,Y) 
&amp; = f(\beta_{0}){\prod_{k=1}^{17} f(\beta_k)} f(Y|x^{cmp},\beta_{0},\beta) \\
&amp; \propto 
f(\beta_{0})
{\prod_{k=1}^{17} f(\beta_k)} 
[\prod_{i=1}^{n} logit^{-1}(\beta_{0} + \beta x_{i})]^{y_{i}}[\prod_{i=1}^{n}(1- logit^{-1}(\beta_{0} + \beta x_{i}))]^{(1- y_{i})}
\end{aligned}
\]</span></p>
<p><strong>Model Diagnostic</strong></p>
<p>Logistic regression does not require the assumptions of constant variance and normality of residuals. To check if the predictors of fitted logistic regression model are well specified, we applied binned residuals technique. The procedures to produce binned residuals include: first, we computed raw residuals of the fitted model and ordered observations by values of predicted probabilities; second, for continuous predictor, we formed <span class="math inline">\(\sqrt{27346} \approx 165\)</span> equally sized, ordered bins using the ordered data and computed average residual of each bin. Next, we plotted average residual versus average predicted probability of each bin to check if there are any specific patterns that might cause problems; third, for categorical predictor, we computed average residual of each level.</p>
<div class="figure" style="text-align: center"><span id="fig:residualsbinned"></span>
<img src="figure/residuals_binned.png" alt="Residuals Binned Plot"  />
<p class="caption">
Figure 6.1: Residuals Binned Plot
</p>
</div>
<p>We created the binned residuals plot (Figure <a href="6-pooled-analysis.html#fig:residualsbinned">6.1</a>) based on one imputed dataset’s model (Frequentist model) results. The average residuals are close to 0 for salary less than $82,425, but tend to fluctuate for salary greater than $82,425. That data with higher salary values are more sparse leads to the fluctuation. For categorical variable, the number of level is limited and majority of the time the prediction would yield 0 (not promoted), and thus, the average residuals for each bin are small. In general, we did not observe extreme residuals, but we should be wary of data with higher salary values.</p>
<table>
<caption>Gender</caption>
<thead>
<tr class="header">
<th align="left">M</th>
<th align="left">F</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(-1.473e^{-10}\)</span></td>
<td align="left"><span class="math inline">\(-1.916e^{-10}\)</span></td>
</tr>
</tbody>
</table>

<table>
<caption>Occupational Category Residuals</caption>
<thead>
<tr class="header">
<th align="left">P</th>
<th align="left">A</th>
<th align="left">O</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(-8.481e^{-11}\)</span></td>
<td align="left"><span class="math inline">\(-2.158e^{-10}\)</span></td>
<td align="left"><span class="math inline">\(-2.186e^{-10}\)</span></td>
</tr>
</tbody>
</table>

<table>
<caption>Education Levels Residuals</caption>
<thead>
<tr class="header">
<th align="left">B</th>
<th align="left">A</th>
<th align="left">C</th>
<th align="left">D</th>
<th align="left">E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(1.847e^{-10}\)</span></td>
<td align="left"><span class="math inline">\(-2.093e^{-10}\)</span></td>
<td align="left"><span class="math inline">\(-1.351e^{-10}\)</span></td>
<td align="left"><span class="math inline">\(-3.733e^{-11}\)</span></td>
<td align="left"><span class="math inline">\(-2.573e^{-11}\)</span></td>
</tr>
</tbody>
</table>

<table>
<caption>Race</caption>
<thead>
<tr class="header">
<th align="left">White</th>
<th align="left">Non-white</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(1.570e^{-10}\)</span></td>
<td align="left"><span class="math inline">\(-1.869e^{-10}\)</span></td>
</tr>
</tbody>
</table>

<table>
<caption>Switch</caption>
<thead>
<tr class="header">
<th align="left">Switch</th>
<th align="left">No-switch</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(-1.549e^{-10}\)</span></td>
<td align="left"><span class="math inline">\(-1.658e^{-10}\)</span></td>
</tr>
</tbody>
</table>

<table>
<caption>Supervisory Position Residuals</caption>
<thead>
<tr class="header">
<th align="left">Supervisor</th>
<th align="left">Non-supervisor</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(-2.010e^{-10}\)</span></td>
<td align="left"><span class="math inline">\(-1.588e^{-10}\)</span></td>
</tr>
</tbody>
</table>

<table>
<caption>Grade</caption>
<thead>
<tr class="header">
<th align="left">Grade0</th>
<th align="left">Grade1</th>
<th align="left">Grade2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(-2.464e^{-10}\)</span></td>
<td align="left"><span class="math inline">\(-5.606e^{-12}\)</span></td>
<td align="left"><span class="math inline">\(-5.440e^{-12}\)</span></td>
</tr>
</tbody>
</table>

<table>
<caption>% Change Residuals</caption>
<thead>
<tr class="header">
<th align="left">Change2</th>
<th align="left">Change1</th>
<th align="left">Change3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(-1.888e^{-10}\)</span></td>
<td align="left"><span class="math inline">\(-1.184e^{-10}\)</span></td>
<td align="left"><span class="math inline">\(-1.351e^{-10}\)</span></td>
</tr>
</tbody>
</table>

</div>
<div id="pooled-results" class="section level2">
<h2><span class="header-section-number">6.2</span> Pooled results</h2>
<p>We combined poole results for both Frequentist model and Bayesian model. For Frequentist model, we obtained the pooled results through (1) averaging out the estimated regression coefficients of each completed dataset (2) accounting for both within and across datasets variances. For Bayesian model, we obtained the pooled results through summarizing the mixture draws from posterior distribution.</p>
<div id="frequentist-model" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Frequentist model</h3>
<p>For each completed dataset <span class="math inline">\(j\)</span> (<span class="math inline">\(j = 1,...,12\)</span>) and each regression coefficient <span class="math inline">\(\beta_{ij}\)</span> (<span class="math inline">\(i = 0,...,17\)</span>), let <span class="math inline">\(q_{ij}\)</span> be the estimator of <span class="math inline">\(\beta_{ij}\)</span> from <span class="math inline">\(j_{th}\)</span> dataset, and let <span class="math inline">\(u_{ij}\)</span> be the estimator of the variance of <span class="math inline">\(\beta_{ij}\)</span> from <span class="math inline">\(j_{th}\)</span> dataset. First, we computed the average of each dataset’s estimated slope to obtain the estimate of the model coefficient <span class="math inline">\(\overline{q_{i}}\)</span>. Second, we computed the average of each dataset’s estimated slope variance to obtain the within-dataset variance <span class="math inline">\(\overline{u_{i}}\)</span>. Thid, we computed the variance of the slopes across 12 datasets to obtain the across-datasets variance <span class="math inline">\(b_{i}\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \overline{q_{i}} = \sum_{j=1}^{12}q_{ij}/12 \\
&amp; \overline{u_{i}} = \sum_{j=1}^{12}u_{ij}/12 \\
&amp; b_{i} = \sum_{j=1}^{12}(q_{ij} -\overline{q_{i}})/(12-1) \\
\end{aligned}
\]</span></p>
<p>With average estimated regression coefficient (<span class="math inline">\(\overline{q_{i}}\)</span>), within-dataset variance (<span class="math inline">\(\overline{u_{i}}\)</span>), and across-datasets variance (<span class="math inline">\(b_{i}\)</span>), the point estimate of <span class="math inline">\(\beta_{i}\)</span> is <span class="math inline">\(\overline{q_{i}}\)</span>, and its variance is <span class="math inline">\(T_{i} = (1+1/12)b_{i}+\overline{u_{i}}\)</span>. An approximate 95% confidence interval is <span class="math inline">\(\overline{q_{i}} \pm 1.96\sqrt{T_{i}}\)</span>. The table below shows the pooled estimated slope, standard error, and 95% confidence interval of each regression coefficient.</p>
<table>
<caption><em>Combined Coefficient Estimate, Standard Error, and 95% CI. (Frequentist Model)</em></caption>
<thead>
<tr class="header">
<th align="left">Coefficient</th>
<th align="left">Estimate</th>
<th align="left">Std. Error</th>
<th align="left">95% CI.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Intercept (<span class="math inline">\(\beta_{0}\)</span>)</td>
<td align="left">-6.018</td>
<td align="left">0.697</td>
<td align="left">[-6.871, -5.164]</td>
</tr>
<tr class="even">
<td align="left">Female (<span class="math inline">\(\beta_{1}\)</span>)</td>
<td align="left">-0.035</td>
<td align="left">0.012</td>
<td align="left">[-0.0815, 0.011]</td>
</tr>
<tr class="odd">
<td align="left">OccA (<span class="math inline">\(\beta_{2}\)</span>)</td>
<td align="left">0.744</td>
<td align="left">0.015</td>
<td align="left">[0.709, 0.779]</td>
</tr>
<tr class="even">
<td align="left">OccO (<span class="math inline">\(\beta_{3}\)</span>)</td>
<td align="left">1.005</td>
<td align="left">0.299</td>
<td align="left">[0.845, 1.170]</td>
</tr>
<tr class="odd">
<td align="left">EducA (<span class="math inline">\(\beta_{4}\)</span>)</td>
<td align="left">-0.712</td>
<td align="left">0.036</td>
<td align="left">[-0.748, -0.675]</td>
</tr>
<tr class="even">
<td align="left">EducC (<span class="math inline">\(\beta_{5}\)</span>)</td>
<td align="left">0.128</td>
<td align="left">0.016</td>
<td align="left">[0.094, 0.161]</td>
</tr>
<tr class="odd">
<td align="left">EducD (<span class="math inline">\(\beta_{6}\)</span>)</td>
<td align="left">0.195</td>
<td align="left">0.033</td>
<td align="left">[0.139, 0.252]</td>
</tr>
<tr class="even">
<td align="left">EducE (<span class="math inline">\(\beta_{7}\)</span>)</td>
<td align="left">-0.047</td>
<td align="left">0.045</td>
<td align="left">[-0.129, 0.036]</td>
</tr>
<tr class="odd">
<td align="left">Non-white (<span class="math inline">\(\beta_{8}\)</span>)</td>
<td align="left">-0.112</td>
<td align="left">0.017</td>
<td align="left">[-0.151, -0.074]</td>
</tr>
<tr class="even">
<td align="left">No-switch (<span class="math inline">\(\beta_{9}\)</span>)</td>
<td align="left">-0.039</td>
<td align="left">0.031</td>
<td align="left">[-0.057, -0.020]</td>
</tr>
<tr class="odd">
<td align="left">Non-Supervisor (<span class="math inline">\(\beta_{10}\)</span>)</td>
<td align="left">-0.949</td>
<td align="left">0.013</td>
<td align="left">[-1.008, -0.890]</td>
</tr>
<tr class="even">
<td align="left">Grade0 (<span class="math inline">\(\beta_{11}\)</span>)</td>
<td align="left">-0.450</td>
<td align="left">0.066</td>
<td align="left">[-0.657, -0.244]</td>
</tr>
<tr class="odd">
<td align="left">Grade2 (<span class="math inline">\(\beta_{12}\)</span>)</td>
<td align="left">1.389</td>
<td align="left">0.049</td>
<td align="left">[1.213,1.565]</td>
</tr>
<tr class="even">
<td align="left">ScaledSalary (<span class="math inline">\(\beta_{13}\)</span>)</td>
<td align="left">1.939</td>
<td align="left">0.618</td>
<td align="left">[1.157, 2.721]</td>
</tr>
<tr class="odd">
<td align="left">(ScaledSalary + 1.0751) (<span class="math inline">\(\beta_{14}\)</span>)</td>
<td align="left">2.919</td>
<td align="left">0.642</td>
<td align="left">[2.077, 3.761]</td>
</tr>
<tr class="even">
<td align="left">(ScaledSalary - 0.2272) (<span class="math inline">\(\beta_{15}\)</span>)</td>
<td align="left">3.328</td>
<td align="left">0.902</td>
<td align="left">[2.362, 4.294]</td>
</tr>
<tr class="odd">
<td align="left">Change1 (<span class="math inline">\(\beta_{16}\)</span>)</td>
<td align="left">-0.266</td>
<td align="left">0.027</td>
<td align="left">[-0.457, -0.074]</td>
</tr>
<tr class="even">
<td align="left">Change3 (<span class="math inline">\(\beta_{17}\)</span>)</td>
<td align="left">0.233</td>
<td align="left">0.025</td>
<td align="left">[0.065, 0.401]</td>
</tr>
</tbody>
</table>
</div>
<div id="bayesian-model" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Bayesian Model</h3>
<p>For Bayesian model, instead of averaging out the estimated regression coefficients, we obtained the pooled results through applying the approach proposed by Zhou and Reiter (2010). For each completed dataset <span class="math inline">\(l = 1,...,m\)</span> and parameter of interest <span class="math inline">\(Q\)</span>, denote <span class="math inline">\(Q^{(l)}\)</span> as the MCMC draws from posterior distribution. First, simulate <span class="math inline">\(J\)</span> values of posterior draws (where <span class="math inline">\(J\)</span> is large) from each <span class="math inline">\(Q^{(l)}\)</span>, with its distribution denoted as <span class="math inline">\(\hat{f}(Q^{(l)})\)</span>. Second, mix all <span class="math inline">\(\hat{f}(Q^{(l)})\)</span> to form <span class="math inline">\(\hat{f}(Q^{(all)})\)</span>. Third, sort total number of <span class="math inline">\(m*J\)</span> draws from <span class="math inline">\(\hat{f}(Q^{(all)})\)</span>, where the estimates of 95% posterior interval, posterior median, and other statistics can be obtained from the mixed posterior draws <span class="citation">(Zhou &amp; Reiter, 2010)</span>.</p>
<p>The pooled estimated slope, standard error, and 95% credible interval are generated through specifying <span class="math inline">\(J = 4000\)</span> to create a total number of <span class="math inline">\(12*4000 = 48000\)</span> draws. The table below shows the pooled estimated slope, standard error, and 95% credible interval of each regression coefficient.</p>
<table>
<caption><em>Combined Coefficient Estimate, Standard Error, and 95% CI. (Frequentist’s Model)</em></caption>
<thead>
<tr class="header">
<th align="left">Coefficient</th>
<th align="left">Estimate</th>
<th align="left">Std. Error</th>
<th align="left">95% CI.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Intercept (<span class="math inline">\(\beta_{0}\)</span>)</td>
<td align="left">-6.033</td>
<td align="left">0.816</td>
<td align="left">[-7.732, -4.529]</td>
</tr>
<tr class="even">
<td align="left">Female (<span class="math inline">\(\beta_{1}\)</span>)</td>
<td align="left">-0.036</td>
<td align="left">0.110</td>
<td align="left">[-0.254, 0.176]</td>
</tr>
<tr class="odd">
<td align="left">OccA (<span class="math inline">\(\beta_{2}\)</span>)</td>
<td align="left">0.745</td>
<td align="left">0.124</td>
<td align="left">[0.502, 0.988]</td>
</tr>
<tr class="even">
<td align="left">OccO (<span class="math inline">\(\beta_{3}\)</span>)</td>
<td align="left">0.877</td>
<td align="left">0.571</td>
<td align="left">[-0.359, 1.887]</td>
</tr>
<tr class="odd">
<td align="left">EducA (<span class="math inline">\(\beta_{4}\)</span>)</td>
<td align="left">-0.719</td>
<td align="left">0.191</td>
<td align="left">[-1.103, -0.354]</td>
</tr>
<tr class="even">
<td align="left">EducC (<span class="math inline">\(\beta_{5}\)</span>)</td>
<td align="left">0.127</td>
<td align="left">0.127</td>
<td align="left">[-0.123, 0.375]</td>
</tr>
<tr class="odd">
<td align="left">EducD (<span class="math inline">\(\beta_{6}\)</span>)</td>
<td align="left">0.190</td>
<td align="left">0.183</td>
<td align="left">[-0.174, 0.542]</td>
</tr>
<tr class="even">
<td align="left">EducE (<span class="math inline">\(\beta_{7}\)</span>)</td>
<td align="left">-0.056</td>
<td align="left">0.212</td>
<td align="left">[-0.479, 0.355]</td>
</tr>
<tr class="odd">
<td align="left">Non-white (<span class="math inline">\(\beta_{8}\)</span>)</td>
<td align="left">-0.116</td>
<td align="left">0.132</td>
<td align="left">[-0.383, 0.140]</td>
</tr>
<tr class="even">
<td align="left">No-switch (<span class="math inline">\(\beta_{9}\)</span>)</td>
<td align="left">-0.029</td>
<td align="left">0.178</td>
<td align="left">[-0.365, 0.326]</td>
</tr>
<tr class="odd">
<td align="left">Non-Supervisor (<span class="math inline">\(\beta_{10}\)</span>)</td>
<td align="left">-0.950</td>
<td align="left">0.112</td>
<td align="left">[-1.167, -0.729]</td>
</tr>
<tr class="even">
<td align="left">Grade0 (<span class="math inline">\(\beta_{11}\)</span>)</td>
<td align="left">-0.458</td>
<td align="left">0.253</td>
<td align="left">[-0.966, 0.025]</td>
</tr>
<tr class="odd">
<td align="left">Grade2 (<span class="math inline">\(\beta_{12}\)</span>)</td>
<td align="left">1.395</td>
<td align="left">0.218</td>
<td align="left">[0.969, 1.823]</td>
</tr>
<tr class="even">
<td align="left">ScaledSalary (<span class="math inline">\(\beta_{13}\)</span>)</td>
<td align="left">1.933</td>
<td align="left">0.770</td>
<td align="left">[0.530, 3.559]</td>
</tr>
<tr class="odd">
<td align="left">(ScaledSalary + 1.0751) (<span class="math inline">\(\beta_{14}\)</span>)</td>
<td align="left">2.915</td>
<td align="left">0.781</td>
<td align="left">[1.476, 4.538]</td>
</tr>
<tr class="even">
<td align="left">(ScaledSalary - 0.2272) (<span class="math inline">\(\beta_{15}\)</span>)</td>
<td align="left">3.316</td>
<td align="left">0.927</td>
<td align="left">[1.573, 5.205]</td>
</tr>
<tr class="odd">
<td align="left">Change1 (<span class="math inline">\(\beta_{16}\)</span>)</td>
<td align="left">-0.268</td>
<td align="left">0.159</td>
<td align="left">[-0.586, 0.032]</td>
</tr>
<tr class="even">
<td align="left">Change3 (<span class="math inline">\(\beta_{17}\)</span>)</td>
<td align="left">0.231</td>
<td align="left">0.154</td>
<td align="left">[-0.078, 0.521]</td>
</tr>
</tbody>
</table>
</div>
<div id="comparison-between-frequentist-and-bayesian-model" class="section level3">
<h3><span class="header-section-number">6.2.3</span> Comparison between Frequentist and Bayesian Model</h3>
<p>We compared the pooled results for both Frequentist model (Figure <a href="6-pooled-analysis.html#fig:frequentist">6.2</a>) and Bayesian model (Figure <a href="6-pooled-analysis.html#fig:bayesian">6.3</a>). The pooled coefficient means of both models are close to each other, but Bayesian model has higher pooled standard errors. There are certain requirements for Bayesian inference after multiple imputation. Our inherent constraints - prior parameter choices and number of available imputed datasets therefore lead to greater uncertainty. First, the posterior distribution depends on the choice of prior parameter, which usually requires knowledge from experts. Our choice of non-informative prior might not be the most ideal prior. Second, Zhou and Reiter <span class="citation">(Zhou &amp; Reiter, 2010)</span> suggested that the number of imputed datasets should be large (at least 100 imputed datasets) in order for Bayesian inference to work well. Since there are only 12 available imputed datasets, Bayesian inference might not be valid. Thus, we conducted inference based on the Frequentist model.</p>
<div class="figure" style="text-align: center"><span id="fig:frequentist"></span>
<img src="figure/Frequentist.png" alt="Frequentist Model"  />
<p class="caption">
Figure 6.2: Frequentist Model
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:bayesian"></span>
<img src="figure/Bayesian.png" alt="Bayesian Model"  />
<p class="caption">
Figure 6.3: Bayesian Model
</p>
</div>
</div>
</div>
<div id="inference-based-on-frequentist-model" class="section level2">
<h2><span class="header-section-number">6.3</span> Inference based on Frequentist model</h2>
<p>In general, the selection of the SES positions is highly dependent on (1) personal skills (indicated by variable <em>Occupational Category</em> and <em>Supervisory Status</em>) (2) education level (indicated by variable <em>Education Group</em>) and (3) performance at work (indicated by variable <em>Salary</em>, <em>Grade</em>, and <em>Change in Pay Rate</em>)</p>
<p>First, for employees whose occupational category are <em>Administrative</em>, the odds of getting promoted are multiplied by a factor of 2.104 (95% CI: 2.031 to 2.180) compared to employees whose occupational category are <em>Professional</em>, holding all else constant. This implies that analytical ability, judgment, discretion, and personal responsibility (characteristics of occupational category <em>Administrative</em>) might be more important than having knowledge in a specific field of science (characteristics of occupational category <em>Professional</em>). Furthermore, for employees who do not serve in supervisory positions, the odds of getting promoted are multiplied by a factor of 0.387 (95% CI: 0.365 to 0.411) than employees who serve in supervisory positions, holding all else constant. Since leadership is one of the key competencies for the SES positions, employees without leadership experiences might be put into disadvantages.</p>
<p>Second, education level also plays an important role when it comes to predicting promotion outcome. For employees with degrees below Bachelor’s, the odds of getting promoted is multiplied by 0.491 (95% CI: 0.473 to 0.509) compared to employees with Bachelor’s degree, holding all else constant. Furthermore, though it is expected that the odds of getting promoted would increase with higher education level, there is certain limit. Specifically, compared to employees with only Bachelor’s degrees, the odds of getting promoted increases if employees acquired Master’s and Advanced degrees. However, the effect of PhD degrees on predicting promotion is not significant because its 95% confidence interval contains 0. Because PhD degrees focus on particular fields of studies, this result further confirms that having specific knowledge in a field of science might not be one of the important promotion criteria.</p>
<p>Third, compared to employees with grade 13 and 14 at working year 10, the odds of getting promoted are multiplied by a factor of 0.637 (95% CI: 0.519 to 0.784) for employees with grade below 13, but multiplied by a factor of 4.010 (95% CI: 3.364 to 4.781) for employees with grade 15. The visualization graphs further show the relationship between salary at given grade and % change in salary (Grade 15 for Figure <a href="6-pooled-analysis.html#fig:grade15">6.4</a>, Grade 14 for Figure <a href="6-pooled-analysis.html#fig:grade14">6.5</a>, Grade 13 for Figure <a href="6-pooled-analysis.html#fig:grade13">6.6</a>, Grade &lt; 13 for Figure <a href="6-pooled-analysis.html#fig:less13">6.7</a>). Regardless of Grade, the predicted probability of getting promoted increases as salary increases, and employees with bigger percentage change in salary also have higher odds of getting promoted. Note that the model yields predicted probability up to 0.25 at Grade 15. Given the small proportion of ones, we believe that the predicted probability at grade 15 is potentially overestimated due to sparsity of the data at higher salary values.</p>
<div class="figure" style="text-align: center"><span id="fig:grade15"></span>
<img src="figure/Grade15.png" alt="Grade 15"  />
<p class="caption">
Figure 6.4: Grade 15
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:grade14"></span>
<img src="figure/Grade14.png" alt="Grade 14"  />
<p class="caption">
Figure 6.5: Grade 14
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:grade13"></span>
<img src="figure/Grade13.png" alt="Grade 13"  />
<p class="caption">
Figure 6.6: Grade 13
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:less13"></span>
<img src="figure/less13.png" alt="Grade &lt; 13"  />
<p class="caption">
Figure 6.7: Grade &lt; 13
</p>
</div>
<p>Lastly, the 95% confidence interval of variable <em>Gender</em> contains value 0, suggesting that the effect of <em>Gender</em> is not significant in predicting promotion outcome. For employees whose race are <em>Non-white</em>, the odds of getting promoted are multiplied by a factor of 0.894 (95% CI: 0.868 to 0.929) compared to employees whose race are <em>White</em>, holding all else constant.</p>
</div>
<div id="conclusion-and-future-improvement" class="section level2">
<h2><span class="header-section-number">6.4</span> Conclusion and future improvement</h2>
<p>In conclusion, the model suggests an employee’s personal skills and performance at work are significant in predicting promotion outcomes, but certain limitations exist for the model. First, the analysis is currently based on 10% samples of the OPM database, and we would like to apply our current model on the data with full samples to test its predictive accuracy. Second, the predictive probability of employees with very high salary values is overestimated. This might due to the fact that the piecewise linear model is not granular enough to account for small proportion of ones in outcome variables. In the future, we would like to experiment on various semi-parametric and parametric models. Third, we did not have enough imputed datasets to account for random noises produced by the imputation models. This also affected the validity of the Bayesian inference after multiple imputation. In the future, we would like to expand the current computational capacity in order to impute more completed datasets.</p>

<!--
The bib chunk below must go last in this document according to how R Markdown renders.  More info is at http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html
-->

<!-- 
If you'd like to change the name of the bibliography to something else,
delete "References" and replace it.
-->
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="5-model-fitting.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
