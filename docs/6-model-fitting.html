<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title></title>
  <meta name="description" content="">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="" />
  
  
  

<meta name="author" content="Jerry Chia-Rui Chang">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="5-modeling-of-imputed-dataset.html">
<link rel="next" href="7-pooled-analysis.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> hello</a></li>
<li class="chapter" data-level="" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="2" data-path="2-introduction.html"><a href="2-introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="3-data.html"><a href="3-data.html"><i class="fa fa-check"></i><b>3</b> Data</a><ul>
<li class="chapter" data-level="3.1" data-path="3-data.html"><a href="3-data.html#introduction-of-data"><i class="fa fa-check"></i><b>3.1</b> Introduction of Data</a></li>
<li class="chapter" data-level="3.2" data-path="3-data.html"><a href="3-data.html#identify-sub-population"><i class="fa fa-check"></i><b>3.2</b> Identify Sub-population</a></li>
<li class="chapter" data-level="3.3" data-path="3-data.html"><a href="3-data.html#missing-data"><i class="fa fa-check"></i><b>3.3</b> Missing Data</a></li>
<li class="chapter" data-level="3.4" data-path="3-data.html"><a href="3-data.html#assessing-missing-data"><i class="fa fa-check"></i><b>3.4</b> Assessing Missing Data</a></li>
<li class="chapter" data-level="3.5" data-path="3-data.html"><a href="3-data.html#addressing-missing-data"><i class="fa fa-check"></i><b>3.5</b> Addressing Missing Data</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-imputation-of-missing-data.html"><a href="4-imputation-of-missing-data.html"><i class="fa fa-check"></i><b>4</b> Imputation of Missing Data</a><ul>
<li class="chapter" data-level="4.1" data-path="4-imputation-of-missing-data.html"><a href="4-imputation-of-missing-data.html#overview-of-multiple-imputation"><i class="fa fa-check"></i><b>4.1</b> Overview of Multiple Imputation</a></li>
<li class="chapter" data-level="4.2" data-path="4-imputation-of-missing-data.html"><a href="4-imputation-of-missing-data.html#specifying-predictive-conditional-distribution---the-cart-method"><i class="fa fa-check"></i><b>4.2</b> Specifying Predictive Conditional Distribution - the CART method</a></li>
<li class="chapter" data-level="4.3" data-path="4-imputation-of-missing-data.html"><a href="4-imputation-of-missing-data.html#improving-computational-efficiency"><i class="fa fa-check"></i><b>4.3</b> Improving Computational Efficiency</a></li>
<li class="chapter" data-level="4.4" data-path="4-imputation-of-missing-data.html"><a href="4-imputation-of-missing-data.html#imputation-results-and-posterior-predictive-checks"><i class="fa fa-check"></i><b>4.4</b> Imputation Results and Posterior Predictive Checks</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-modeling-of-imputed-dataset.html"><a href="5-modeling-of-imputed-dataset.html"><i class="fa fa-check"></i><b>5</b> Modeling of Imputed Dataset</a><ul>
<li class="chapter" data-level="5.1" data-path="5-modeling-of-imputed-dataset.html"><a href="5-modeling-of-imputed-dataset.html#outcome-variable-and-selection-of-covariates"><i class="fa fa-check"></i><b>5.1</b> Outcome Variable and Selection of Covariates</a></li>
<li class="chapter" data-level="5.2" data-path="5-modeling-of-imputed-dataset.html"><a href="5-modeling-of-imputed-dataset.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>5.2</b> Exploratory Data Analysis</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-model-fitting.html"><a href="6-model-fitting.html"><i class="fa fa-check"></i><b>6</b> Model Fitting</a><ul>
<li class="chapter" data-level="6.1" data-path="6-model-fitting.html"><a href="6-model-fitting.html#spline-logistic-regression"><i class="fa fa-check"></i><b>6.1</b> Spline Logistic Regression</a></li>
<li class="chapter" data-level="6.2" data-path="6-model-fitting.html"><a href="6-model-fitting.html#frequentist---maximum-likelihood-approach"><i class="fa fa-check"></i><b>6.2</b> Frequentist - Maximum Likelihood Approach</a></li>
<li class="chapter" data-level="6.3" data-path="6-model-fitting.html"><a href="6-model-fitting.html#bayesian---posterior-distribution"><i class="fa fa-check"></i><b>6.3</b> Bayesian - Posterior Distribution</a></li>
<li class="chapter" data-level="6.4" data-path="6-model-fitting.html"><a href="6-model-fitting.html#final-model"><i class="fa fa-check"></i><b>6.4</b> Final Model</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-pooled-analysis.html"><a href="7-pooled-analysis.html"><i class="fa fa-check"></i><b>7</b> Pooled Analysis</a><ul>
<li class="chapter" data-level="7.1" data-path="7-pooled-analysis.html"><a href="7-pooled-analysis.html#pooled-results"><i class="fa fa-check"></i><b>7.1</b> Pooled Results</a><ul>
<li class="chapter" data-level="7.1.1" data-path="7-pooled-analysis.html"><a href="7-pooled-analysis.html#frequentist-model"><i class="fa fa-check"></i><b>7.1.1</b> Frequentist Model</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-pooled-analysis.html"><a href="7-pooled-analysis.html#bayesian-model"><i class="fa fa-check"></i><b>7.1.2</b> Bayesian Model</a></li>
<li class="chapter" data-level="7.1.3" data-path="7-pooled-analysis.html"><a href="7-pooled-analysis.html#comparison-between-frequentist-and-bayesian-model"><i class="fa fa-check"></i><b>7.1.3</b> Comparison between Frequentist and Bayesian Model</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-pooled-analysis.html"><a href="7-pooled-analysis.html#inference"><i class="fa fa-check"></i><b>7.2</b> Inference</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="model-fitting" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Model Fitting</h1>
<p>According to the results from exploratory data analysis, we fit a model based on one imputed dataset, where model coefficients are computed from two approaches - Frequentist’s Maximum Likelihood Estimation and Bayesian’s Posterior Distribution.</p>
<div id="spline-logistic-regression" class="section level2">
<h2><span class="header-section-number">6.1</span> Spline Logistic Regression</h2>
<p>In Generalized Linear Models (GLMs), the coefficients of predictors on univariate outcome variable Y is usually linear. However, the binnedplot of predictor year 10 salary shows that the relationship between outcome variable and year 10 salary is non-linear. In order to capture the non-linear relationship, one common strategy is to incorporate smoothing techniques such as the application of spline function into the GLMs. A semi-parametric spline logistic regression is therefore used to model the data.</p>
<p>To recap the relationship between year 10 salary and outcome variable, the proportion of ones below certain salary level is relatively flat, whereas the proportion of ones above certain salary level increases significantly. (Figure <a href="6-model-fitting.html#fig:salarybinned2">6.1</a>) This indicates that the coefficient slopes should be different for salary above and below certain level, which can be modeled by a spline function.</p>
<div class="figure" style="text-align: center"><span id="fig:salarybinned2"></span>
<img src="figure/salary_binned2.png" alt="Year 10 Salary Binned Plot"  />
<p class="caption">
Figure 6.1: Year 10 Salary Binned Plot
</p>
</div>
<p>A spline of degree D is a continuous function formed by connecting polynomial segments. The points where the segments connect are called the knots of the spline. In general, a spline of degree D associated with a knot <span class="math inline">\(\xi_{k}\)</span> takes the form: <span class="math display">\[
(x-\xi_{k})_{+}^{D}= 
\begin{cases}
    0, &amp; x &lt; \xi_{k}\\
    (x-\xi_{k})^{D}, &amp; x \geq \xi_{k}
\end{cases}
\]</span></p>
<p>Because the shapes of both segments (blue and red segments in the binned plot) are close to linear, the degree of the spline function is 1. A knot is chosen as the cut point between the two segments, which takes the value of $77,100. (Since year 10 salary is centered and scaled, this cut point should be <span class="math inline">\(\dfrac{77,180 - 82,425}{10,000} = -0.5425\)</span>.)</p>
<p>Denote <span class="math inline">\(x\)</span> as the year 10 salary after transformation. The equation for the piecewise linear spline is <span class="math display">\[
\begin{aligned}
y &amp; = \beta_{0} + \beta_{1}x + \beta_{2}(x - (-0.5425))_{+} \\
&amp; = \beta_{0} + \beta_{1}x + \beta_{2}(x + 0.5425)(I[x \geq -0.5425])
\end{aligned}
\]</span></p>
<p>If year 10 salary is below the cut point, the coefficient <span class="math inline">\(\beta_{2}\)</span> would be equal to 0. On the other hand, if year 10 salary is above the cut point, the coefficient <span class="math inline">\(\beta_{2}\)</span> would help capture the difference in slopes. To sum up, we can rewrite the above equation as <span class="math display">\[
y = 
\begin{cases}
    \beta_{0} + \beta_{1}x, &amp; x &lt; -0.5425\\
    \beta_{0} + \beta_{1}x + \beta_{2}(x + 0.5425)(I[x \geq -0.5425]), &amp; x \geq -0.5425
\end{cases}
\]</span></p>
<p><strong>Baseline</strong></p>
<p>Other than year 10 salary, the rest of the covariates are categorical variables. Given that the proportion of ones in outcome variable is small, it is important to select reasonable baseline for each categorical variable. For variable <em>Gender</em>, we would like to learn whether women were put in disadvantages during promotion, so male is the baseline. For variable <em>Race</em>, since the population size for white is the largest, white is the baseline. For variable <em>Education Level</em>, Bachelor’s degree is the baseline because it is the most common degree federal employees earned. For variable <em>Department Switch</em>, switch is the baseline. For variable <em>Occupational Category</em>, Professional is the baseline. For variable <em>Supervisory Status</em>, supervisor is the baseline. For variable <em>Year 10 Grade</em>, grade above 13 is the baseline. For variable <em>Change in Pay Rate</em>, change2 (annual rate change between 5-10%) is the baseline.</p>
<p><strong>Model Form (Full Model) </strong></p>
<p>To sum up, the model takes the following form. <span class="math display">\[
\begin{aligned}
logit(p) &amp; = \beta_{0}+ \beta_{1}\text{Female} + \beta_{2}\text{OccA} + \beta_{3}\text{OccO} + \beta_{4}\text{EducA} + \beta_{5}\text{EducC} + \beta_{6}\text{EducD} \\
&amp; + \beta_{7}\text{EducE} +  \beta_{8}\text{Non-White} + \beta_{9}\text{NoSwitch} + \beta_{10}\text{Non-Supervisor} + \beta_{11}\text{Grade0} \\
&amp; + \beta_{12}\text{Salary} + \beta_{13}(\text{Salary} + 0.5425)*I[\text{Salary} \geq 0.5425] + \beta_{14}\text{Change1} + \beta_{15}\text{Change3}
\end{aligned}
\]</span></p>
</div>
<div id="frequentist---maximum-likelihood-approach" class="section level2">
<h2><span class="header-section-number">6.2</span> Frequentist - Maximum Likelihood Approach</h2>
<p><strong>Model Coefficients</strong></p>
<p>In a frequentist setting, the estimation of model coefficients are computed through maximum likelihood approach. The table shows the estimate, standard error, p-value of each coefficient.</p>
<table>
<thead>
<tr class="header">
<th align="left">Coefficient</th>
<th align="left">Estimate</th>
<th align="left">Std. Error</th>
<th align="left">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept) (<span class="math inline">\(\beta_{0}\)</span>)</td>
<td align="left">-5.589</td>
<td align="left">0.706</td>
<td align="left">0.0000000000000024</td>
</tr>
<tr class="even">
<td align="left">Female (<span class="math inline">\(\beta_{1}\)</span>)</td>
<td align="left">-0.026</td>
<td align="left">0.106</td>
<td align="left">0.80787</td>
</tr>
<tr class="odd">
<td align="left">OccA (<span class="math inline">\(\beta_{2}\)</span>)</td>
<td align="left">0.766</td>
<td align="left">0.122</td>
<td align="left">0.0000000003766811</td>
</tr>
<tr class="even">
<td align="left">OccO (<span class="math inline">\(\beta_{3}\)</span>)</td>
<td align="left">1.032</td>
<td align="left">0.539</td>
<td align="left">0.05571</td>
</tr>
<tr class="odd">
<td align="left">EducA (<span class="math inline">\(\beta_{4}\)</span>)</td>
<td align="left">-0.742</td>
<td align="left">0.188</td>
<td align="left">0.0000770642309893</td>
</tr>
<tr class="even">
<td align="left">EducC (<span class="math inline">\(\beta_{5}\)</span>)</td>
<td align="left">0.166</td>
<td align="left">0.125</td>
<td align="left">0.18347</td>
</tr>
<tr class="odd">
<td align="left">EducD (<span class="math inline">\(\beta_{6}\)</span>)</td>
<td align="left">0.240</td>
<td align="left">0.179</td>
<td align="left">0.17915</td>
</tr>
<tr class="even">
<td align="left">EducE (<span class="math inline">\(\beta_{7}\)</span>)</td>
<td align="left">0.005</td>
<td align="left">0.207</td>
<td align="left">0.98274</td>
</tr>
<tr class="odd">
<td align="left">Non-White (<span class="math inline">\(\beta_{8}\)</span>)</td>
<td align="left">-0.098</td>
<td align="left">0.128</td>
<td align="left">0.44430</td>
</tr>
<tr class="even">
<td align="left">No_Switch (<span class="math inline">\(\beta_{9}\)</span>)</td>
<td align="left">-0.067</td>
<td align="left">0.179</td>
<td align="left">0.69805</td>
</tr>
<tr class="odd">
<td align="left">Non-Supervisor (<span class="math inline">\(\beta_{10}\)</span>)</td>
<td align="left">-1.063</td>
<td align="left">0.106</td>
<td align="left">0.0000000000000002</td>
</tr>
<tr class="even">
<td align="left">Grade0 (<span class="math inline">\(\beta_{11}\)</span>)</td>
<td align="left">-0.705</td>
<td align="left">0.224</td>
<td align="left">0.00167</td>
</tr>
<tr class="odd">
<td align="left">Salary (<span class="math inline">\(\beta_{12}\)</span>)</td>
<td align="left">2.067</td>
<td align="left">0.672</td>
<td align="left">0.00210</td>
</tr>
<tr class="even">
<td align="left">(Salary + 0.5425) (<span class="math inline">\(\beta_{13}\)</span>)</td>
<td align="left">5.248</td>
<td align="left">0.706</td>
<td align="left">0.0000000000001042</td>
</tr>
<tr class="odd">
<td align="left">Change1 (<span class="math inline">\(\beta_{14}\)</span>)</td>
<td align="left">-0.441</td>
<td align="left">0.132</td>
<td align="left">0.00086</td>
</tr>
<tr class="even">
<td align="left">Change3 (<span class="math inline">\(\beta_{15}\)</span>)</td>
<td align="left">0.293</td>
<td align="left">0.126</td>
<td align="left">0.01967</td>
</tr>
</tbody>
</table>
<p><em>Gender</em> (<span class="math inline">\(\beta_{1}\)</span>), <em>Race</em> (<span class="math inline">\(\beta_{8}\)</span>), and <em>Switch</em> (<span class="math inline">\(\beta_{9}\)</span>) are not significant in predicting promotion outcomes, with their p-values much greater than 0.05. We further conduct a change in deviance test to better understand the fit of those variables. Specifically, denote <span class="math inline">\(D_{0}\)</span> as the deviance of reduced model (without <em>Gender</em>, <em>Race</em>, and <em>Switch</em>), and <span class="math inline">\(D_{1}\)</span> as the deviance of full model (original model). For large sample size, the difference between <span class="math inline">\(D_{0}\)</span> and <span class="math inline">\(D_{1}\)</span> has a chi-square distribution with degrees of freedom equal to the difference in the number of parameters estimated. The change in deviance test yields a p-value of 0.846, indicating that the inclusion of variable <em>Gender</em>, <em>Race</em>, and <em>Switch</em> does not provide a better fit to the data. Therefore, the reduced model is a better model.</p>
<p><strong>Model Diagnostic</strong></p>
<p>Constant variance and normality of residuals are not assumptions for logistic regression. To check if function of predictor is well specified, binned residuals technique is applied to reduced model. In order to produce binned residuals, we first compute raw residuals for fitted logistic regression model, and order observations by values of predicted probabilities from the fitted regression. Second, for continuous predictor, we form <span class="math inline">\(\sqrt{27346} \approx 165\)</span> equally sized, ordered bins using ordered data, and compute average residual in each bin. For categorical predictor, we compute the average residual in each level. Lastly, we plot average residual versus average predicted probability for each bin, and find specific patterns that might yield problems.</p>
<p>According to binned residuals plot (Figure <a href="6-model-fitting.html#fig:residualsbinned">6.2</a>), the average residuals are close to 0 for scaled salary less than 0 (corresponds to $82,425), but tend to have more fluctuation for scaled salary greater than 0. The fluctuation is caused by small proportion of ones in outcome variable and shouldn’t be of concern. For categorical variable, because the number of level is limited and the prediction would yield 0 (not promoted) majority of the time, the average residuals for each bin are small. (table) In general, no extreme residuals are observed, and we can conclude that the model provides reasonable fit to the data.</p>
<div class="figure" style="text-align: center"><span id="fig:residualsbinned"></span>
<img src="figure/residuals_binned.png" alt="Residuals Binned Plot"  />
<p class="caption">
Figure 6.2: Residuals Binned Plot
</p>
</div>
</div>
<div id="bayesian---posterior-distribution" class="section level2">
<h2><span class="header-section-number">6.3</span> Bayesian - Posterior Distribution</h2>
<p>In addition to estimating the model coefficients through maximum likelihood approach, we further fit a Bayesian Logistics Regression model to verify our results. Bayesian analysis requires the specification of the prior distributions for both the intercept and coefficients. Prior to seeing the data, we assume that the intercept (<span class="math inline">\(\beta_{0}\)</span>) and the coefficients of the predictors (<span class="math inline">\(\beta = \beta_{1}, ..., \beta_{j}\)</span>) have normal distribution with mean 0 and variance 5 - that <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta\)</span> are as likely to be positive as they are to be negative but unlikely to be far away from zero.</p>
<p>After observing the data, the likelihood of each observation can be modeled as a binomial distribution <span class="math inline">\(p(x_{i},y_{i}|\beta_{0},\beta) = Binomial(1, \pi_{i})\)</span> for <span class="math inline">\(i = 1,...,n\)</span>; <span class="math inline">\(\pi_{i}\)</span> is the probability of getting promoted, where <span class="math inline">\(\pi_{i} = logit^{-1}(\beta_{0} + \beta x_{i}) = \dfrac{exp(\beta_{0} + \beta x_{i})}{1 +exp(\beta_{0} + \beta x_{i}) }\)</span>. The posterior distribution is proportional to the product of the priors and the likelihood distribution. To sum up, the posterior distribution is derived as below.</p>
<p><strong>Prior Distribution</strong> <span class="math display">\[
\begin{aligned}
f(\beta_{0}) &amp;= N(0,5)\\
f(\beta_{k}) &amp;= N(0,5), k = 1,...,15 \\
\end{aligned}
\]</span></p>
<p><strong>Likelihood</strong> <span class="math display">\[
\begin{aligned}
p(X,Y|\beta_{0},\beta) 
&amp; = \prod_{i=1}^{n} p(x_{i},y_{i}|\beta_{0},\beta) \\
&amp; = \prod_{i=1}^{n} {1 \choose y_{i}} (\dfrac{exp(\beta_{0} + \beta x_{i})}{1 +exp(\beta_{0} + \beta x_{i})})^{y_{i}}(\dfrac{1}{1 +exp(\beta_{0} + \beta x_{i})})^{1-y_{i}}\\
&amp; = {n \choose \sum y_{i}} (\prod_{i=1}^{n}\dfrac{exp(\beta_{0} + \beta x_{i})}{1 +exp(\beta_{0} + \beta x_{i})})^{\sum y_{i}}(\prod_{i=1}^{n}\dfrac{1}{1 +exp(\beta_{0} + \beta x_{i})})^{n-\sum y_{i}} \\
&amp; = {n \choose \sum y_{i}} (\prod_{i=1}^{n} logit^{-1}(\beta_{0} + \beta x_{i}))^{\sum y_{i}}(\prod_{i=1}^{n}(1- logit^{-1}(\beta_{0} + \beta x_{i})))^{n-\sum y_{i}} \\
&amp; \propto (\prod_{i=1}^{n} logit^{-1}(\beta_{0} + \beta x_{i}))^{\sum y_{i}}(\prod_{i=1}^{n}(1- logit^{-1}(\beta_{0} + \beta x_{i})))^{n-\sum y_{i}} \\
\end{aligned}
\]</span></p>
<p><strong>Posterior Distribution</strong> <span class="math display">\[
\begin{aligned}
f(\beta_{0},\beta|X,Y) 
&amp; = f(\beta_{0}){\prod_{k=1}^{j} f(\beta_k)} f(X,Y|\beta_{0},\beta) \\
&amp; \propto 
f(\beta_{0})
{\prod_{k=1}^{j} f(\beta_k)} 
(\prod_{i=1}^{n} logit^{-1}(\beta_{0} + \beta x_{i}))^{\sum y_{i}}(\prod_{i=1}^{n}(1- logit^{-1}(\beta_{0} + \beta x_{i})))^{n-\sum y_{i}}
\end{aligned}
\]</span></p>
<p>The 95% posterior interval graph (Figure <a href="6-model-fitting.html#fig:Bayesianfull">6.3</a>) are produced by fitting a Bayesian logistic regression model on all 15 predictors. The median of predictors <em>Gender</em>, <em>Race</em>, and <em>Switch</em> in the graph are close to 0, indicating that these variables do not provide predictive power on the outcome variable. The Bayesian model yields similar results to maximum likelihood approach, where the change in deviance test also suggests that variable <em>Gender</em>, <em>Race</em>, and <em>Switch</em> are not significant.</p>
<div class="figure" style="text-align: center"><span id="fig:Bayesianfull"></span>
<img src="figure/Bayesianfull.png" alt="Bayesian Full Model"  />
<p class="caption">
Figure 6.3: Bayesian Full Model
</p>
</div>
</div>
<div id="final-model" class="section level2">
<h2><span class="header-section-number">6.4</span> Final Model</h2>
<p>The results from both Frequentist and Bayesian suggest that the reduced model is a better model than the full model, which takes the following form: <span class="math display">\[
\begin{aligned}
logit(p) &amp; = \beta_{0} + \beta_{1}\text{OccA} + \beta_{2}\text{OccO} + \beta_{3}\text{EducA} + \beta_{4}\text{EducC} + \beta_{5}\text{EducD} \\
&amp; + \beta_{6}\text{EducE} +  \beta_{7}\text{Non-Supervisor} + \beta_{8}\text{Grade0} \\
&amp; + \beta_{9}\text{Salary} + \beta_{10}(\text{Salary} + 0.5425)*I[\text{Salary} \geq 0.5425] + \beta_{11}\text{Change1} + \beta_{12}\text{Change3}
\end{aligned}
\]</span></p>
<p>In the next chapter, we would combine model results of 12 imputed datasets, and conduct inference based on the pooled model coefficients.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="5-modeling-of-imputed-dataset.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="7-pooled-analysis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
